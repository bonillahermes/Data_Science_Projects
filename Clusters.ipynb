{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyPImWsKi/H0hkmLmTVxZGWT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bonillahermes/Data_Science_Projects/blob/main/Clusters.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hermes Yate Bonilla\n",
        "**Data Scientist**\n",
        "---\n",
        "\n",
        "**Contact:**\n",
        "- **Email:** [bonillahermes@gmail.com](mailto:bonillahermes@gmail.com)\n",
        "- **LinkedIn:** [linkedin.com/in/bonillahermes](https://www.linkedin.com/in/bonillahermes/)\n",
        "- **GitHub:** [github.com/bonillahermes](https://github.com/bonillahermes)\n",
        "- **Webpage:** [bonillahermes.com](https://bonillahermes.com/)\n",
        "---"
      ],
      "metadata": {
        "id": "w4Tsbpv17UIQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h3FV0GNzvtfT"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from sklearn.decomposition import PCA\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.cluster import DBSCAN\n",
        "from scipy import stats\n",
        "from scipy.cluster.hierarchy import dendrogram, linkage\n",
        "from scipy.cluster.hierarchy import fcluster\n",
        "from sklearn.cluster import SpectralClustering\n",
        "from sklearn.mixture import GaussianMixture\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "import plotly.graph_objs as go\n",
        "from sklearn.datasets import load_digits\n",
        "from scipy.stats import f_oneway"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "GwPNUdTGvy60"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"/content/drive/My Drive/Bases/DatosSenImput.xlsx\"\n",
        "df = pd.read_excel(path)"
      ],
      "metadata": {
        "id": "uIkIaIgVv3fI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Primero, excluimos la columna 'ID' del análisis pero la guardamos para usarla más adelante si es necesario\n",
        "id_data = df['ID']\n",
        "analysis_data = df.drop(columns=['ID'])"
      ],
      "metadata": {
        "id": "8lF6OjBzW3px"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PCA"
      ],
      "metadata": {
        "id": "LbGlE4egZZMU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "El Análisis de Componentes Principales (PCA, por sus siglas en inglés) es una técnica estadística de reducción de dimensionalidad que se utiliza ampliamente para simplificar la complejidad en conjuntos de datos de alta dimensión al transformarlos a un nuevo sistema de coordenadas de menor dimensión. Las nuevas dimensiones, denominadas componentes principales, se generan de tal manera que el primer componente principal captura la mayor varianza posible de los datos, y cada componente subsiguiente, en orden de extracción, tiene la mayor varianza posible bajo la restricción de ser ortogonal a los anteriores.\n",
        "\n",
        "La metodología del PCA implica un proceso matemático que transforma las variables originales correlacionadas en un conjunto de variables no correlacionadas. Este proceso comienza con la estandarización de las variables de escala para cada dimensión del conjunto de datos. Luego, se calcula la matriz de covarianza o correlación para identificar las relaciones entre ellas. A partir de esta matriz, se obtienen los autovalores y autovectores que reflejan la magnitud y la dirección de la varianza en los datos. Los autovectores se convierten en los componentes principales, y los autovalores indican la cantidad de varianza que cada componente principal retiene.\n",
        "\n",
        "La utilidad del PCA en un entorno profesional es multiforme. En el contexto del análisis exploratorio de datos, permite identificar patrones y visualizar la estructura de los datos de manera simplificada. En el ámbito de la construcción de modelos predictivos, el PCA se utiliza para mitigar problemas de multicolinealidad y reducir el tiempo computacional, seleccionando solo aquellos componentes que aportan la mayoría de la información. Además, en campos como la bioinformática y la investigación de mercado, el PCA se emplea para agrupar y clasificar datos complejos de forma intuitiva."
      ],
      "metadata": {
        "id": "ZFxL5HrPMDss"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Aplicar PCA\n",
        "pca = PCA(n_components=5)\n",
        "datos_pca = pca.fit_transform(analysis_data)"
      ],
      "metadata": {
        "id": "vUkDhiD2ZbEX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Varianza explicada por cada componente\n",
        "varianza_explicada = pca.explained_variance_ratio_\n",
        "varianza_acumulada = np.cumsum(varianza_explicada)"
      ],
      "metadata": {
        "id": "izEpGNulZcIT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(varianza_explicada)\n",
        "print(varianza_acumulada)"
      ],
      "metadata": {
        "id": "xj07wRKxZi4_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear gráfico de la varianza explicada acumulada\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.bar(range(1, len(varianza_explicada) + 1), varianza_explicada, alpha=0.5, align='center', label='Varianza explicada individual')\n",
        "plt.step(range(1, len(varianza_acumulada) + 1), varianza_acumulada, where='mid', label='Varianza explicada acumulada')\n",
        "plt.ylabel('Porcentaje de varianza explicada')\n",
        "plt.xlabel('Componentes principales')\n",
        "plt.legend(loc='best')\n",
        "plt.title('Análisis de Componentes Principales - Varianza Explicada')\n",
        "plt.axhline(y=0.95, color='r', linestyle='--', label='95% varianza explicada')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "4jAaNdG8Znrh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Aplicar PCA con 5 componentes\n",
        "pca = PCA(n_components=5)\n",
        "pca.fit(analysis_data)\n",
        "datos_pca = pca.transform(analysis_data)\n",
        "\n",
        "# Obtener las cargas (loadings) de PCA\n",
        "loadings = pca.components_.T * np.sqrt(pca.explained_variance_)\n",
        "\n",
        "# Crear un DataFrame para los loadings y los nombres de las variables\n",
        "loadings_df = pd.DataFrame(loadings, index=analysis_data.columns, columns=[f'Component {i+1}' for i in range(5)])\n",
        "\n",
        "# Crear una lista para almacenar la asignación de variables a componentes\n",
        "component_assignments = []\n",
        "\n",
        "# Iterar sobre cada variable y su loading en cada componente\n",
        "for variable in loadings_df.index:\n",
        "    for component in loadings_df.columns:\n",
        "        loading = loadings_df.loc[variable, component]\n",
        "        if abs(loading) >= 0.4:  # Criterio de umbral\n",
        "            component_assignments.append((variable, component, loading))\n",
        "\n",
        "# Convertir la lista en un DataFrame\n",
        "component_assignments_df = pd.DataFrame(component_assignments, columns=['Variable', 'Component', 'Loading'])\n",
        "\n",
        "# Mostrar los resultados\n",
        "print(component_assignments_df)"
      ],
      "metadata": {
        "id": "f-tP-WIDZtqD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "component_assignments_df.to_excel('component_assignments_df.xlsx', engine='openpyxl')  # Guardar en un archivo CSV si se necesita"
      ],
      "metadata": {
        "id": "hM4DK4mzZyxI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear un DataFrame con los puntajes de PCA y los IDs correspondientes\n",
        "scores_df = pd.DataFrame(datos_pca, columns=[f'Component {i+1}' for i in range(5)])\n",
        "scores_df['ID'] = id_data\n",
        "\n",
        "# Función para encontrar los individuos más representativos para cada componente\n",
        "def top_contributors(component, n=5):\n",
        "    return scores_df[['ID', component]].sort_values(by=component, ascending=False).head(n)\n",
        "\n",
        "# Aplicar la función para cada componente y almacenar en un diccionario\n",
        "top_contributors_by_component = {f'Component {i+1}': top_contributors(f'Component {i+1}') for i in range(5)}\n",
        "\n",
        "# Mostrar los resultados\n",
        "for component, top_contributors_df in top_contributors_by_component.items():\n",
        "    print(f'Top contributors for {component}:')\n",
        "    print(top_contributors_df, '\\n')"
      ],
      "metadata": {
        "id": "ppSdaaOvmq9I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Kmeans"
      ],
      "metadata": {
        "id": "DHwTVLNslnYe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Determinación de números de clusters"
      ],
      "metadata": {
        "id": "3AX604mt1rNh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcular la suma de las distancias al cuadrado para un rango de número de clusters\n",
        "inertia = []\n",
        "for n in range(1, 10):\n",
        "    kmeans = KMeans(n_clusters=n, random_state=42).fit(datos_pca)\n",
        "    inertia.append(kmeans.inertia_)\n",
        "\n",
        "# Graficar el método del codo\n",
        "plt.figure(figsize=(20, 10))\n",
        "plt.plot(range(1, 10), inertia, marker='o')\n",
        "plt.title('Método del Codo para Determinar el Número Óptimo de Clusters')\n",
        "plt.xlabel('Número de Clusters')\n",
        "plt.ylabel('Inertia')\n",
        "plt.xticks(range(1, 10))\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ikauiKt0_r_P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "En el gráfico del método del codo, se puede observar cómo disminuye la inercia a medida que aumenta el número de clusters. Lo que se busca en un gráfico de este tipo es un cambio en la tasa de disminución que se asemeje a un \"codo\". En el gráfico, este punto no es extremadamente pronunciado, pero parece que podría haber un codo alrededor del cluster 3 o 4. Después de este punto, la inercia sigue disminuyendo pero a un ritmo más lento, lo que sugiere que añadir más clusters más allá de este punto no mejora la suma de distancias cuadradas dentro de los clusters."
      ],
      "metadata": {
        "id": "1LYUqrp-_tbS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kmeans = KMeans(n_clusters=3, random_state=42)  # Ajustar K-means\n",
        "clusters = kmeans.fit_predict(datos_pca)"
      ],
      "metadata": {
        "id": "DfILyKahBhJA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear DataFrame para los resultados\n",
        "resultados_pca = pd.DataFrame(datos_pca, columns=[f'PC{i+1}' for i in range(5)])\n",
        "resultados_pca['Cluster'] = clusters\n",
        "resultados_pca['ID'] = id_data\n",
        "\n",
        "# Guardar en formato Excel\n",
        "resultados_pca.to_excel('resultados_pca_clusters.xlsx', index=False)"
      ],
      "metadata": {
        "id": "vABJ2V1NEgaZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear DataFrame para los componentes principales\n",
        "pca_df = pd.DataFrame(datos_pca, columns=[f'PC{i+1}' for i in range(5)])\n",
        "\n",
        "# Añadir los componentes y los clusters al DataFrame original\n",
        "df_final = df.join(pca_df)\n",
        "df_final['Cluster'] = clusters\n",
        "\n",
        "# Guardar en formato Excel\n",
        "df_final.to_excel('df_con_pca_clusters.xlsx', index=False)"
      ],
      "metadata": {
        "id": "XPVNO0NjFHlo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(datos_pca[:, 0], datos_pca[:, 1], c=clusters, cmap='viridis')\n",
        "plt.xlabel('Componente Principal 1')\n",
        "plt.ylabel('Componente Principal 2')\n",
        "plt.title('Clustering con PCA')\n",
        "plt.colorbar()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "s_WJGZYy-s8L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Configurar PCA para 3 componentes principales\n",
        "pca = PCA(n_components=3)\n",
        "datos_pca_3d = pca.fit_transform(analysis_data)\n",
        "\n",
        "# Aplicar K-Means\n",
        "kmeans = KMeans(n_clusters=3, random_state=42)\n",
        "clusters = kmeans.fit_predict(datos_pca_3d)"
      ],
      "metadata": {
        "id": "NpzREruDBcME"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear un gráfico de dispersión 3D interactivo con plotly\n",
        "fig = go.Figure(data=[go.Scatter3d(\n",
        "    x=datos_pca_3d[:, 0],\n",
        "    y=datos_pca_3d[:, 1],\n",
        "    z=datos_pca_3d[:, 2],\n",
        "    mode='markers',\n",
        "    text=id_data,  # Utilizar id_data para los tooltips\n",
        "    hoverinfo='text+name',  # Mostrar el texto (ID) en los tooltips\n",
        "    marker=dict(\n",
        "        size=5,\n",
        "        color=clusters,  # Asignar colores de acuerdo a las etiquetas de cluster\n",
        "        colorscale='Viridis',  # Escala de color de Plotly\n",
        "        opacity=0.8\n",
        "    )\n",
        ")])\n",
        "\n",
        "# Actualizar el diseño del gráfico para añadir título y etiquetas\n",
        "fig.update_layout(\n",
        "    title='Clustering con PCA en 3D',\n",
        "    scene=dict(\n",
        "        xaxis_title='Componente Principal 1',\n",
        "        yaxis_title='Componente Principal 2',\n",
        "        zaxis_title='Componente Principal 3'\n",
        "    ),\n",
        "    legend_title=\"Clusters\"\n",
        ")\n",
        "\n",
        "# Mostrar el gráfico\n",
        "fig.show()\n"
      ],
      "metadata": {
        "id": "dTSQtzPUBSvy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filtrar por el clúster 1\n",
        "mask_cluster1 = clusters == 0\n",
        "fig1 = go.Figure(data=[go.Scatter3d(\n",
        "    x=datos_pca_3d[mask_cluster1, 0],\n",
        "    y=datos_pca_3d[mask_cluster1, 1],\n",
        "    z=datos_pca_3d[mask_cluster1, 2],\n",
        "    mode='markers',\n",
        "    text=np.array(id_data)[mask_cluster1],  # Asumiendo que id_data es una lista o array\n",
        "    hoverinfo='text+name',\n",
        "    marker=dict(\n",
        "        size=5,\n",
        "        color='purple',  # Color estático para el clúster 1\n",
        "        opacity=0.8\n",
        "    )\n",
        ")])\n",
        "\n",
        "fig1.update_layout(\n",
        "    title='Clúster 1 con PCA en 3D',\n",
        "    scene=dict(\n",
        "        xaxis_title='Componente Principal 1',\n",
        "        yaxis_title='Componente Principal 2',\n",
        "        zaxis_title='Componente Principal 3'\n",
        "    )\n",
        ")\n",
        "fig1.show()\n"
      ],
      "metadata": {
        "id": "W0XrhkuH578U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filtrar por el clúster 2\n",
        "mask_cluster1 = clusters == 1\n",
        "fig1 = go.Figure(data=[go.Scatter3d(\n",
        "    x=datos_pca_3d[mask_cluster1, 0],\n",
        "    y=datos_pca_3d[mask_cluster1, 1],\n",
        "    z=datos_pca_3d[mask_cluster1, 2],\n",
        "    mode='markers',\n",
        "    text=np.array(id_data)[mask_cluster1],  # Asumiendo que id_data es una lista o array\n",
        "    hoverinfo='text+name',\n",
        "    marker=dict(\n",
        "        size=5,\n",
        "        color='skyblue',  # Color estático para el clúster 2\n",
        "        opacity=0.8\n",
        "    )\n",
        ")])\n",
        "\n",
        "fig1.update_layout(\n",
        "    title='Clúster 1 con PCA en 3D',\n",
        "    scene=dict(\n",
        "        xaxis_title='Componente Principal 1',\n",
        "        yaxis_title='Componente Principal 2',\n",
        "        zaxis_title='Componente Principal 3'\n",
        "    )\n",
        ")\n",
        "fig1.show()"
      ],
      "metadata": {
        "id": "KXWrKo2H6O4A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filtrar por el clúster 3\n",
        "mask_cluster1 = clusters == 2\n",
        "fig1 = go.Figure(data=[go.Scatter3d(\n",
        "    x=datos_pca_3d[mask_cluster1, 0],\n",
        "    y=datos_pca_3d[mask_cluster1, 1],\n",
        "    z=datos_pca_3d[mask_cluster1, 2],\n",
        "    mode='markers',\n",
        "    text=np.array(id_data)[mask_cluster1],  # Asumiendo que id_data es una lista o array\n",
        "    hoverinfo='text+name',\n",
        "    marker=dict(\n",
        "        size=5,\n",
        "        color='yellow',  # Color estático para el clúster 1\n",
        "        opacity=0.8\n",
        "    )\n",
        ")])\n",
        "\n",
        "fig1.update_layout(\n",
        "    title='Clúster 1 con PCA en 3D',\n",
        "    scene=dict(\n",
        "        xaxis_title='Componente Principal 1',\n",
        "        yaxis_title='Componente Principal 2',\n",
        "        zaxis_title='Componente Principal 3'\n",
        "    )\n",
        ")\n",
        "fig1.show()"
      ],
      "metadata": {
        "id": "2Ic1f0t06Sde"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Añadir las etiquetas de los clusters al DataFrame de puntajes PCA\n",
        "scores_df = pd.DataFrame(datos_pca, columns=[f'Component {i+1}' for i in range(5)])\n",
        "scores_df['Cluster'] = clusters\n",
        "\n",
        "# Calcular los centros medios de cada cluster para cada componente\n",
        "cluster_centers_df = scores_df.groupby('Cluster').mean()"
      ],
      "metadata": {
        "id": "VcWLl9_yofED"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualización de los centros de los clusters en cada componente\n",
        "cluster_centers_df.plot(kind='bar', figsize=(14, 7))\n",
        "plt.ylabel('Valor Medio del Componente')\n",
        "plt.xlabel('Cluster')\n",
        "plt.legend(title='Componentes', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qkY59BOHocEt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 7))\n",
        "for i in range(1, 6):\n",
        "    plt.subplot(2, 3, i)\n",
        "    sns.boxplot(x='Cluster', y=f'Component {i}', data=scores_df)\n",
        "    plt.title(f'Distribución del Componente {i} por Cluster')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "jEEhydhdq74E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "descriptive_stats = scores_df.groupby('Cluster').describe().stack(level=0)[['mean', 'std', 'min', '25%', '50%', '75%', 'max']]\n",
        "\n",
        "# Imprime las estadísticas descriptivas para revisarlas\n",
        "print(descriptive_stats)"
      ],
      "metadata": {
        "id": "4-ye5F_iwX0T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear un DataFrame con las componentes principales y las etiquetas de clúster\n",
        "df_pca = pd.DataFrame(datos_pca, columns=['PC1', 'PC2', 'PC3', 'PC4', 'PC5'])\n",
        "df_pca['cluster'] = clusters\n",
        "\n",
        "# Realizar ANOVA para cada componente principal\n",
        "results = {}\n",
        "for i in range(1, 6):  # Asumiendo que hay 3 componentes principales\n",
        "    groups = [df_pca[df_pca['cluster'] == k][f'PC{i}'] for k in range(3)]\n",
        "    f_value, p_value = f_oneway(*groups)\n",
        "    results[f'PC{i}'] = (f_value, p_value)\n",
        "\n",
        "# Imprimir los resultados del ANOVA\n",
        "for component, (f_val, p_val) in results.items():\n",
        "    print(f'{component} - F-Value: {f_val}, P-Value: {p_val}')\n",
        "    if p_val < 0.05:\n",
        "        print(f\"Existen diferencias estadísticamente significativas para {component} entre los grupos.\")\n",
        "    else:\n",
        "        print(f\"No hay diferencias estadísticamente significativas para {component} entre los grupos.\")\n"
      ],
      "metadata": {
        "id": "7lFU-Wt_Pw31"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## t-SNE"
      ],
      "metadata": {
        "id": "zWkWG7OySq3o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Rango de perplejidades para probar\n",
        "perplexities = [5, 10, 30, 50]\n",
        "\n",
        "for perplexity in perplexities:\n",
        "    tsne = TSNE(n_components=3, verbose=1, perplexity=perplexity, n_iter=3000, random_state=42)\n",
        "    Y = tsne.fit_transform(analysis_data)\n",
        "\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    plt.scatter(Y[:, 0], Y[:, 1], c='blue')\n",
        "    plt.title(f't-SNE with Perplexity={perplexity}')\n",
        "    plt.xlabel('Component 1')\n",
        "    plt.ylabel('Component 2')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "_ojup7BPgGdg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Configurar t-SNE con una semilla para obtener resultados reproducibles\n",
        "tsne = TSNE(n_components=3, verbose=1, perplexity=5, n_iter=5000, random_state=42)\n",
        "datos_tsne = tsne.fit_transform(analysis_data)"
      ],
      "metadata": {
        "id": "cJvspLGlSknN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Gráfico de los datos en 2D\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(datos_tsne[:, 0], datos_tsne[:, 1])\n",
        "plt.xlabel('t-SNE feature 1')\n",
        "plt.ylabel('t-SNE feature 2')\n",
        "plt.title('Visualización t-SNE')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "fqZSvwU30moF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Kmeans"
      ],
      "metadata": {
        "id": "QK3OuYHiSv_z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# datos_tsne contiene los datos de t-SNE\n",
        "wcss = []\n",
        "for i in range(1, 11):\n",
        "    kmeans = KMeans(n_clusters=i, init='k-means++', max_iter=300, n_init=10, random_state=0)\n",
        "    kmeans.fit(datos_tsne)\n",
        "    wcss.append(kmeans.inertia_)\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "plt.plot(range(1, 11), wcss)\n",
        "plt.title('El Método del Codo')\n",
        "plt.xlabel('Número de clusters')\n",
        "plt.ylabel('WCSS')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "_WHKknRhmXJD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Kmeans\n",
        "kmeans = KMeans(n_clusters=3)  # Ajustar el número de clusters según la necesidad del análisis\n",
        "cluster_labels_kmeans = kmeans.fit_predict(datos_tsne)  # Realizar el clustering\n",
        "\n",
        "# Visualizar los clusters\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(datos_tsne[:, 0], datos_tsne[:, 1], c=cluster_labels_kmeans, cmap='viridis', s=50, alpha=0.6, edgecolor='k')  # s: tamaño de punto, alpha: transparencia, edgecolor: color del borde de los puntos\n",
        "plt.xlabel('t-SNE feature 1')\n",
        "plt.ylabel('t-SNE feature 2')\n",
        "plt.title('Clusters K-Means sobre t-SNE')\n",
        "plt.colorbar()  # Mostrar la leyenda de colores para los clusters\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "yggvuOGC5Vzt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear un gráfico de dispersión 3D interactivo con plotly\n",
        "fig = go.Figure(data=[go.Scatter3d(\n",
        "    x=datos_tsne[:, 0],\n",
        "    y=datos_tsne[:, 1],\n",
        "    z=datos_tsne[:, 2],\n",
        "    mode='markers',\n",
        "    text=id_data,  # Usar id_data para los tooltips\n",
        "    hoverinfo='text+name',  # Mostrar el texto (ID) y el nombre del trace (útil para identificar los clusters)\n",
        "    marker=dict(\n",
        "        size=5,\n",
        "        color=cluster_labels_kmeans,  # Asignar colores de acuerdo a las etiquetas de cluster\n",
        "        colorscale='Viridis',  # Escala de color de Plotly\n",
        "        opacity=0.6,\n",
        "        line=dict(\n",
        "            color='Black',  # Color de los bordes de los puntos\n",
        "            width=0.5       # Ancho de los bordes\n",
        "        )\n",
        "    )\n",
        ")])\n",
        "\n",
        "# Actualizar el diseño del gráfico para añadir título y etiquetas\n",
        "fig.update_layout(\n",
        "    title='Clusters K-Means sobre t-SNE en 3D',\n",
        "    scene=dict(\n",
        "        xaxis_title='t-SNE feature 1',\n",
        "        yaxis_title='t-SNE feature 2',\n",
        "        zaxis_title='t-SNE feature 3'\n",
        "    ),\n",
        "    legend_title=\"Clusters\"\n",
        ")\n",
        "\n",
        "# Mostrar el gráfico\n",
        "fig.show()\n"
      ],
      "metadata": {
        "id": "x_oCeDqX86lC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DBSCAN"
      ],
      "metadata": {
        "id": "fCAK40-YacQY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 'eps' y 'min_samples' son parámetros clave que pueden necesitar ajustes basados en la densidad y distribución de los datos\n",
        "dbscan = DBSCAN(eps=0.6, min_samples=3)\n",
        "cluster_labels_dbscan = dbscan.fit_predict(datos_tsne)  # Realizar el clustering con los datos de t-SNE\n",
        "\n",
        "# Visualizar los clusters\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(datos_tsne[:, 0], datos_tsne[:, 1], c=cluster_labels_dbscan, cmap='viridis', s=50, alpha=0.5, edgecolor='k')  # Mejoras visuales\n",
        "plt.xlabel('t-SNE feature 1')\n",
        "plt.ylabel('t-SNE feature 2')\n",
        "plt.title('Clusters DBSCAN sobre t-SNE')\n",
        "plt.colorbar(label='Cluster Label')  # Aclarar que la barra de colores representa las etiquetas de los clusters\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "QIlKEieu5Yr4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# UMAP"
      ],
      "metadata": {
        "id": "13z8RO-3U5UE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install umap-learn"
      ],
      "metadata": {
        "id": "D6chlNa3WM8V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import umap"
      ],
      "metadata": {
        "id": "w8BA93YKVzZi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Definir rangos para los parámetros\n",
        "neighbor_space = np.arange(5, 50, 15)  # Explora desde 5 vecinos hasta 50, en pasos de 15\n",
        "min_dist_space = np.arange(0.1, 0.6, 0.2)  # Explora desde 0.1 hasta 0.5, en pasos de 0.2\n",
        "\n",
        "fig, axs = plt.subplots(len(neighbor_space), len(min_dist_space), figsize=(15, 12))\n",
        "\n",
        "for i, n_neighbors in enumerate(neighbor_space):\n",
        "    for j, min_dist in enumerate(min_dist_space):\n",
        "        umap_reducer = umap.UMAP(n_neighbors=n_neighbors, min_dist=min_dist, random_state=42, n_components=2)\n",
        "        embedding = umap_reducer.fit_transform(analysis_data)\n",
        "        ax = axs[i, j]\n",
        "        scatter = ax.scatter(embedding[:, 0], embedding[:, 1], c='blue', cmap='Spectral', s=5)\n",
        "        ax.set_title(f\"Neighbors: {n_neighbors}, Min_dist: {min_dist}\")\n",
        "        ax.xaxis.set_major_formatter(plt.NullFormatter())\n",
        "        ax.yaxis.set_major_formatter(plt.NullFormatter())\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_FoFfaDjowu5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Configurar UMAP\n",
        "reducer = umap.UMAP(n_neighbors=20, min_dist=0.30, random_state=42, n_components=3)\n",
        "datos_umap = reducer.fit_transform(analysis_data)  # Usar datos sin la columna 'ID'"
      ],
      "metadata": {
        "id": "D04Q5his3wVK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Gráfico de los datos en 2D\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(datos_umap[:, 0], datos_umap[:, 1], alpha=0.5, cmap='viridis', s=50, edgecolor='k')  # s: tamaño de punto, alpha: transparencia, edgecolor: color del borde de los puntos\n",
        "plt.xlabel('UMAP feature 1')\n",
        "plt.ylabel('UMAP feature 2')\n",
        "plt.title('Visualización UMAP de los Datos')\n",
        "plt.grid(True)\n",
        "plt.colorbar(label='Cluster Label')  # Aclarar que la barra de colores representa las etiquetas de los clusters, si aplicable\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "hZm8tION0yWR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Kmeans"
      ],
      "metadata": {
        "id": "IHUhOQXaaBBw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# datos_tsne contiene tus datos de t-SNE\n",
        "wcss = []\n",
        "for i in range(1, 11):\n",
        "    kmeans = KMeans(n_clusters=i, init='k-means++', max_iter=300, n_init=10, random_state=0)\n",
        "    kmeans.fit(datos_umap)\n",
        "    wcss.append(kmeans.inertia_)\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "plt.plot(range(1, 11), wcss)\n",
        "plt.title('El Método del Codo')\n",
        "plt.xlabel('Número de clusters')\n",
        "plt.ylabel('WCSS')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "JPJ7fGl6sPlY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Asumiendo que 'datos_umap' contiene los resultados de UMAP\n",
        "kmeans = KMeans(n_clusters=2)  # Define el número de clusters adecuado\n",
        "cluster_labels = kmeans.fit_predict(datos_umap)  # Realizar el clustering\n",
        "\n",
        "# Visualizar los clusters\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(datos_umap[:, 0], datos_umap[:, 1], c=cluster_labels, cmap='viridis', alpha=0.5)\n",
        "plt.title('Clusters K-Means sobre UMAP')\n",
        "plt.xlabel('UMAP feature 1')\n",
        "plt.ylabel('UMAP feature 2')\n",
        "plt.colorbar()  # Mostrar la leyenda de colores para los clusters\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "cpyIg-v53Bos"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear un gráfico de dispersión 3D interactivo con plotly\n",
        "fig = go.Figure(data=[go.Scatter3d(\n",
        "    x=datos_umap[:, 0],\n",
        "    y=datos_umap[:, 1],\n",
        "    z=datos_umap[:, 2],\n",
        "    mode='markers',\n",
        "    text=id_data,  # Utilizar id_data para los tooltips\n",
        "    hoverinfo='text',  # Mostrar el texto (ID) en los tooltips\n",
        "    marker=dict(\n",
        "        size=5,\n",
        "        color=cluster_labels,  # Asignar colores de acuerdo a las etiquetas de cluster\n",
        "        colorscale='Viridis',  # Escala de color de Plotly\n",
        "        opacity=0.8\n",
        "    )\n",
        ")])\n",
        "\n",
        "# Actualizar el diseño del gráfico para añadir título y etiquetas\n",
        "fig.update_layout(\n",
        "    title='Clusters K-Means sobre UMAP en 3D',\n",
        "    scene=dict(\n",
        "        xaxis_title='UMAP feature 1',\n",
        "        yaxis_title='UMAP feature 2',\n",
        "        zaxis_title='UMAP feature 3'\n",
        "    ),\n",
        "    legend_title=\"Clusters\"\n",
        ")\n",
        "\n",
        "# Mostrar el gráfico\n",
        "fig.show()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "q6E0gc8G2vHS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DBSCAN"
      ],
      "metadata": {
        "id": "de3BavKvaHyj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ajustar los parámetros de DBSCAN según sea necesario\n",
        "dbscan = DBSCAN(eps=0.6, min_samples=5)  # Ajusta 'eps' y 'min_samples' según tus datos\n",
        "dbscan_labels = dbscan.fit_predict(datos_umap)  # Realizar el clustering\n",
        "\n",
        "# Visualizar los clusters\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(datos_umap[:, 0], datos_umap[:, 1], c=dbscan_labels, cmap='viridis', alpha=0.5)\n",
        "plt.title('Clusters DBSCAN sobre UMAP')\n",
        "plt.xlabel('UMAP feature 1')\n",
        "plt.ylabel('UMAP feature 2')\n",
        "plt.colorbar()  # Mostrar la leyenda de colores para los clusters\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "MjuqFMTn4hwP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Clustering Jerarquico"
      ],
      "metadata": {
        "id": "k5KMAaZwaB1R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "El clustering jerárquico es una técnica de análisis de datos utilizada para detectar y agrupar patrones o conjuntos de observaciones dentro de un gran conjunto de datos. La metodología subyacente del clustering jerárquico no requiere la especificación previa del número de clusters a identificar, a diferencia de otros métodos de clustering como K-Means.\n",
        "\n",
        "Este método construye una jerarquía de clusters, que se visualiza comúnmente en un dendrograma. El dendrograma es una representación gráfica que muestra la secuencia de fusiones o divisiones de clusters a lo largo del proceso de análisis. Cada fusión se representa con una bifurcación en el dendrograma, donde la altura de la bifurcación refleja la distancia o disimilitud entre los clusters que se están uniendo.\n",
        "\n",
        "Existen dos enfoques principales en el clustering jerárquico: el aglomerativo y el divisivo. El enfoque aglomerativo, el más común, comienza tratando cada observación como un cluster individual y fusiona sucesivamente los pares de clusters más cercanos hasta que todas las observaciones están contenidas en un solo cluster. Por otro lado, el enfoque divisivo comienza con todas las observaciones en un solo cluster y procede dividiendo sucesivamente los clusters hasta que cada observación forma su propio cluster.\n",
        "\n",
        "El resultado del clustering jerárquico proporciona no solo una partición de los datos, sino también una representación de las observaciones que refleja tanto las estructuras anidadas como la relación entre los grupos a diferentes niveles de similitud. Este aspecto lo hace particularmente útil en áreas donde las estructuras de los datos son intrínsecamente jerárquicas, como en la biología para la clasificación de especies, en la organización de bibliotecas de documentos o en la segmentación de mercados en marketing.\n",
        "\n",
        "En la práctica profesional, el clustering jerárquico es apreciado por su flexibilidad y la riqueza interpretativa de sus resultados. La capacidad de visualizar y evaluar la cohesión y separación de los datos a diferentes niveles de agrupamiento facilita la toma de decisiones basadas en una comprensión detallada de las estructuras de datos subyacentes."
      ],
      "metadata": {
        "id": "96YUcXVkaoP2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Enlazar usando el método de Ward\n",
        "linked = linkage(datos_pca, 'ward')\n",
        "\n",
        "# Dibujar el dendrograma\n",
        "plt.figure(figsize=(10, 7))\n",
        "dendrogram(linked, orientation='top', distance_sort='descending', show_leaf_counts=True)\n",
        "plt.title('Dendrograma de Clustering Jerárquico')\n",
        "plt.xlabel('Número de muestra')\n",
        "plt.ylabel('Distancia')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "sdcMmiB4av73"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Queremos cortar el dendrograma a una distancia de 100\n",
        "clusters = fcluster(linked, t=48, criterion='distance')\n",
        "\n",
        "# Añadir los labels de los clusters al DataFrame original\n",
        "df['Cluster_Label'] = clusters\n",
        "\n",
        "# Ahora 'df' contiene una nueva columna 'Cluster_Label' que indica a qué cluster pertenece cada observación"
      ],
      "metadata": {
        "id": "x2QiVuRWbDYS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcular estadísticas descriptivas para cada cluster\n",
        "cluster_stats = df.groupby('Cluster_Label').agg(['mean', 'median', 'std', 'min', 'max'])\n",
        "\n",
        "# Ahora, puedes imprimir o explorar 'cluster_stats' para obtener una visión general de cada cluster\n",
        "print(cluster_stats)"
      ],
      "metadata": {
        "id": "V80NIZaybFKl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Para visualizar las diferencias entre los clusters, seleccionemos una característica para ver cómo se distribuye\n",
        "# Reemplaza 'feature_to_plot' con el nombre real de tu característica\n",
        "feature_to_plot = 'IR9'\n",
        "\n",
        "# Crear un boxplot para cada cluster\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.boxplot(x='Cluster_Label', y=feature_to_plot, data=df)\n",
        "plt.title('Distribución de la característica por Cluster')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "hORCkvh4bd9G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Diagrama de violín que proporciona más información sobre la densidad\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.violinplot(x='Cluster_Label', y=feature_to_plot, data=df)\n",
        "plt.title('Distribución de la característica por Cluster')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "AkZzisWYbk8q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lista para guardar los resultados del ANOVA\n",
        "anova_results = []\n",
        "\n",
        "# Iterar sobre cada columna numérica para realizar ANOVA\n",
        "for column in analysis_data.columns:\n",
        "    # Preparar los datos para ANOVA\n",
        "    group_data = [df[df['Cluster_Label'] == label][column] for label in df['Cluster_Label'].unique()]\n",
        "\n",
        "    # Realizar ANOVA y guardar el p-valor\n",
        "    f_val, p_val = stats.f_oneway(*group_data)\n",
        "    anova_results.append({'Variable': column, 'F-Value': f_val, 'P-Value': p_val})\n",
        "\n",
        "# Convertir los resultados en un DataFrame\n",
        "anova_df = pd.DataFrame(anova_results)\n",
        "\n",
        "# Añadir una columna que indica si las diferencias son significativas\n",
        "alpha = 0.05  # Nivel de significancia\n",
        "anova_df['Significant Difference'] = anova_df['P-Value'] < alpha\n",
        "\n",
        "# Mostrar los resultados\n",
        "anova_df"
      ],
      "metadata": {
        "id": "UIDIeyIQbuDF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Análisis Factorial"
      ],
      "metadata": {
        "id": "H50SlHt-g41R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "El Análisis Factorial es una técnica estadística utilizada para describir la variabilidad entre variables observadas correlacionadas en términos de un número potencialmente menor de variables no observadas, llamadas factores. La idea principal es que las observaciones influenciadas por un conjunto de factores subyacentes pueden representar la información esencial en un espacio de dimensiones reducido.\n",
        "\n",
        "En el análisis factorial, se asume que las correlaciones entre las variables observadas se deben a su comunalidad, es decir, a su compartición de uno o más factores comunes. El proceso implica estimar la carga de cada factor, que representa la contribución de cada factor a la variable observada, y la varianza única, que es la parte de la varianza que es única para la variable y no es compartida con otros factores.\n",
        "\n",
        "### Diferencias entre PCA y Análisis Factorial:\n",
        "\n",
        "### Objetivo:\n",
        "- PCA: Orientado a la maximización de la varianza total explicada por los componentes extraídos. Se utiliza para reducir la dimensionalidad manteniendo la mayor cantidad posible de la variabilidad original.\n",
        "- Análisis Factorial: Busca modelar la correlación entre las variables en términos de un número de factores subyacentes. Está más enfocado en identificar la estructura subyacente y los constructos latentes que explican las correlaciones entre las variables.\n",
        "\n",
        "### Modelo Estadístico:\n",
        "- PCA: No distingue entre varianza común y única; cada componente principal incluye una parte de la varianza total (común y única).\n",
        "- Análisis Factorial: Se diferencia entre varianza común (compartida entre variables y atribuible a los factores) y varianza única (específica de cada variable).\n",
        "\n",
        "### Interpretación de Componentes/Factores:\n",
        "\n",
        "- PCA: Los componentes son combinaciones lineales de las variables observadas y pueden no ser interpretables.\n",
        "- Análisis Factorial: Los factores están pensados para ser interpretados y etiquetados como constructos latentes.\n",
        "\n",
        "### Rotación:\n",
        "\n",
        "- PCA: Los componentes son ortogonales entre sí y no están sujetos a rotación.\n",
        "- Análisis Factorial: Se permite la rotación de los factores para mejorar la interpretabilidad, que puede ser ortogonal o oblicua, permitiendo la correlación entre los factores."
      ],
      "metadata": {
        "id": "AIp53iT6PdH6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install factor_analyzer"
      ],
      "metadata": {
        "id": "N_THzdH8Bx2_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from factor_analyzer import FactorAnalyzer\n"
      ],
      "metadata": {
        "id": "k2tVF8Gyhgtb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Inicializar el objeto FactorAnalyzer con el número de factores que deseas extraer y el método de rotación\n",
        "fa = FactorAnalyzer(n_factors=5, rotation='varimax', method='principal')\n",
        "fa.fit(analysis_data)"
      ],
      "metadata": {
        "id": "2wDA0m7ZiCYh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtener la varianza explicada de cada factor\n",
        "factor_variance = fa.get_factor_variance()\n",
        "\n",
        "# Crear un DataFrame para mostrar la varianza explicada\n",
        "variance_df = pd.DataFrame({\n",
        "    'Total Variance': factor_variance[0],\n",
        "    'Proportional Variance': factor_variance[1],\n",
        "    'Cumulative Variance': factor_variance[2]\n",
        "}, index=[f'Factor {i+1}' for i in range(5)])  # Se indexa desde 1 a 5 para incluir los primeros 5 factores\n",
        "\n",
        "print(variance_df)\n"
      ],
      "metadata": {
        "id": "Mp9n8TegpCxL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtener la varianza de cada factor\n",
        "ev, v = fa.get_eigenvalues()"
      ],
      "metadata": {
        "id": "6BCc1JKwrnZh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear un scree plot para visualizar la varianza explicada por cada factor\n",
        "plt.figure(figsize=(10, 7))  # Ajustar el tamaño del gráfico para una mejor visualización\n",
        "plt.scatter(range(1, analysis_data.shape[1]+1), ev)\n",
        "plt.plot(range(1, analysis_data.shape[1]+1), ev)\n",
        "plt.title('Scree Plot para Análisis Factorial')\n",
        "plt.xlabel('Número de Factores')\n",
        "plt.ylabel('Valor Propio (Eigenvalue)')\n",
        "plt.axhline(y=1, color='r', linestyle='--')  # Línea para el criterio de Kaiser\n",
        "plt.text(5, 1.05, 'Criterio de Kaiser', color = 'red')  # Texto para explicar la línea de corte de Kaiser\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "hFyBt-XSBuHy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " Basado en este scree plot, un punto de partida sería considerar entre 5 y 6 factores para el análisis subsiguiente. Sin embargo, esto debe ser informado por un entendimiento más profundo de los datos y el contexto en el que se aplicará el análisis factorial."
      ],
      "metadata": {
        "id": "u8MLT1G4jUB7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Inicializar el objeto FactorAnalyzer con 5 factores y rotación varimax\n",
        "fa = FactorAnalyzer(n_factors=5, rotation='varimax')\n",
        "fa.fit(analysis_data)\n",
        "\n",
        "# Obtener las cargas factoriales (loadings) de las variables\n",
        "loadings = fa.loadings_\n",
        "\n",
        "# Crear un DataFrame para los loadings y los nombres de las variables\n",
        "loadings_df = pd.DataFrame(loadings, index=analysis_data.columns, columns=[f'Factor {i+1}' for i in range(5)])\n",
        "\n",
        "# Crear una función para identificar el factor dominante para cada variable\n",
        "def identify_dominant_factor(loadings, threshold=0.4):\n",
        "    dominant_factor = None\n",
        "    max_loading = threshold\n",
        "    for i, loading in enumerate(loadings):\n",
        "        if abs(loading) >= max_loading:\n",
        "            dominant_factor = i + 1  # Factor numbering starts at 1\n",
        "            max_loading = abs(loading)\n",
        "    return dominant_factor\n",
        "\n",
        "# Aplicar la función a cada fila y guardar los resultados en un DataFrame separado\n",
        "factor_assignments = pd.DataFrame(index=loadings_df.index, columns=['Factor', 'Loading'])\n",
        "for variable in loadings_df.index:\n",
        "    dominant_factor = identify_dominant_factor(loadings_df.loc[variable], threshold=0.4)\n",
        "    if dominant_factor:\n",
        "        factor_assignments.loc[variable, 'Factor'] = f'Factor {dominant_factor}'\n",
        "        factor_assignments.loc[variable, 'Loading'] = loadings_df.loc[variable, f'Factor {dominant_factor}']\n"
      ],
      "metadata": {
        "id": "flzkW9styHCn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Muestra las primeras filas del resultado\n",
        "print(factor_assignments)"
      ],
      "metadata": {
        "id": "bgBreJfqyQGm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "factor_assignments.to_excel('factor_assignments.xlsx', engine='openpyxl')"
      ],
      "metadata": {
        "id": "Ch1R8TF_y0vp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}