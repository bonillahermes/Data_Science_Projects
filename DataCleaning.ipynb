{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyNWUGp07JSEIy+NaBkrTbrv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bonillahermes/Data_Science_Projects/blob/main/DataCleaning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hermes Yate Bonilla\n",
        "**Data Scientist**\n",
        "---\n",
        "\n",
        "**Contact:**\n",
        "- **Email:** [bonillahermes@gmail.com](mailto:bonillahermes@gmail.com)\n",
        "- **LinkedIn:** [linkedin.com/in/bonillahermes](https://www.linkedin.com/in/bonillahermes/)\n",
        "- **GitHub:** [github.com/bonillahermes](https://github.com/bonillahermes)\n",
        "- **Webpage:** [bonillahermes.com](https://bonillahermes.com/)\n",
        "---"
      ],
      "metadata": {
        "id": "nA_R7jXqPePj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Limpieza de datos"
      ],
      "metadata": {
        "id": "N8nCrafHHSAl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VVsAaeIUUK1A"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "# Monta tu Google Drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import scipy.stats as stats\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.express as px\n",
        "from scipy.stats import shapiro"
      ],
      "metadata": {
        "id": "bDQFNVfLUcme"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ruta del archivo Excel en tu Google Drive\n",
        "ruta_archivo = '/content/drive/MyDrive/Bases/BaseJose1.xlsx'\n",
        "\n",
        "# Cargar el archivo Excel en un DataFrame de Pandas\n",
        "data = pd.read_excel(ruta_archivo)\n",
        "\n",
        "# Mostrar las primeras filas para entender la estructura\n",
        "data.head()"
      ],
      "metadata": {
        "id": "l03I4Ic8UiyA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Información general sobre el DataFrame\n",
        "info = data.info()"
      ],
      "metadata": {
        "id": "P48v5a4mUjoN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Valores nulos\n",
        "valores_nulos = data.isnull().sum()\n",
        "valores_nulos"
      ],
      "metadata": {
        "id": "qaNE3-M7UozY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear un diccionario de mapeo para la variable de género\n",
        "mapeo_genero = {\n",
        "    'Masculino': 0,\n",
        "    'Femenino': 1\n",
        "}\n",
        "\n",
        "# Aplicar la conversión y actualizar el DataFrame original para la columna P109\n",
        "data['P109'] = data['P109'].replace(mapeo_genero)"
      ],
      "metadata": {
        "id": "P4Qz7JPGcWt_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convertir las variables P111, P112, P113, P114 y P116\n",
        "variables_si_no = ['P111', 'P112', 'P113', 'P114', 'P116']\n",
        "data[variables_si_no] = data[variables_si_no].replace({'Si': 1, 'No': 0})\n",
        "\n",
        "# Convertir las variables P124, P125, P126, P127 y P128\n",
        "variables_relacionadas = ['P124', 'P125', 'P126', 'P127', 'P128']\n",
        "conversion_relacionadas = {\n",
        "    'No se relaciona': 1,\n",
        "    'Muy poco relacionada': 2,\n",
        "    'Algo relacionada': 3,\n",
        "    'Relacionada': 4,\n",
        "    'Muy relacionada': 5\n",
        "}\n",
        "data[variables_relacionadas] = data[variables_relacionadas].replace(conversion_relacionadas)\n"
      ],
      "metadata": {
        "id": "6qKnLPiGYKLg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear un diccionario de mapeo\n",
        "mapeo_representativo = {\n",
        "    'Nada representativo': 1,\n",
        "    'Poco representativo': 2,\n",
        "    'Medianamente representativo': 3,\n",
        "    'Bastante representativo': 4,\n",
        "    'Completamente representativo': 5\n",
        "}\n",
        "\n",
        "# Lista de las columnas para aplicar la conversión\n",
        "variables_representativas = [\n",
        "    'P129', 'P130', 'P131', 'P132', 'P133',\n",
        "    'P134', 'P135', 'P136', 'P140', 'P141', 'P142', 'P143'\n",
        "]\n",
        "\n",
        "# Aplicar la conversión y actualizar el DataFrame original\n",
        "data[variables_representativas] = data[variables_representativas].replace(mapeo_representativo)\n"
      ],
      "metadata": {
        "id": "WMbBOMNSZaxl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear un diccionario de mapeo\n",
        "mapeo_capaz = {\n",
        "    'Nada capaz': 1,\n",
        "    'Poco capaz': 2,\n",
        "    'Medianamente capaz': 3,\n",
        "    'Bastante capaz': 4,\n",
        "    'Completamente capaz': 5\n",
        "}\n",
        "\n",
        "# Lista de las columnas para aplicar la conversión\n",
        "variables_capaces = ['P144', 'P145', 'P146', 'P147']\n",
        "\n",
        "# Aplicar la conversión y actualizar el DataFrame original\n",
        "data[variables_capaces] = data[variables_capaces].replace(mapeo_capaz)\n"
      ],
      "metadata": {
        "id": "-a4jHYEHZhkr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear un diccionario de mapeo\n",
        "mapeo_acuerdo = {\n",
        "    'Muy en desacuerdo': 1,\n",
        "    'En desacuerdo': 2,\n",
        "    'Ni de acuerdo ni en desacuerdo': 3,\n",
        "    'De acuerdo': 4,\n",
        "    'Muy de acuerdo': 5\n",
        "}\n",
        "\n",
        "# Lista de las columnas para aplicar la conversión\n",
        "variables_acuerdo = [\n",
        "    'P148', 'P149', 'P150', 'P151', 'P152', 'P153',\n",
        "    'P154', 'P155', 'P156', 'P157', 'P158', 'P159'\n",
        "]\n",
        "\n",
        "# Aplicar la conversión y actualizar el DataFrame original\n",
        "data[variables_acuerdo] = data[variables_acuerdo].replace(mapeo_acuerdo)\n"
      ],
      "metadata": {
        "id": "jJZrZSSPaXHH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear un diccionario de mapeo\n",
        "mapeo_acuerdo_desacuerdo = {\n",
        "    'Completamente en desacuerdo': 1,\n",
        "    'En desacuerdo': 2,\n",
        "    'Indiferente': 3,\n",
        "    'De acuerdo': 4,\n",
        "    'Completamente de acuerdo': 5\n",
        "}\n",
        "\n",
        "# Lista de las columnas para aplicar la conversión\n",
        "variables_acuerdo_desacuerdo = [\n",
        "    'P160', 'P161', 'P162', 'P163', 'P164', 'P165', 'P166', 'P167',\n",
        "    'P168', 'P169', 'P170', 'P171', 'P172', 'P173', 'P174', 'P175',\n",
        "    'P176', 'P177', 'P178', 'P179'\n",
        "]\n",
        "\n",
        "# Aplicar la conversión y actualizar el DataFrame original\n",
        "data[variables_acuerdo_desacuerdo] = data[variables_acuerdo_desacuerdo].replace(mapeo_acuerdo_desacuerdo)\n"
      ],
      "metadata": {
        "id": "1chAf8UUa8xv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear un diccionario de mapeo\n",
        "mapeo_descripcion = {\n",
        "    'No me describe': 1,\n",
        "    'Me describe poco': 2,\n",
        "    'Me describe': 3,\n",
        "    'Me describe mucho': 4\n",
        "}\n",
        "\n",
        "# Lista de las columnas para aplicar la conversión\n",
        "variables_descripcion = [\n",
        "    'P180', 'P181', 'P182', 'P183', 'P184',\n",
        "    'P185', 'P186', 'P187', 'P188'\n",
        "]\n",
        "\n",
        "# Aplicar la conversión y actualizar el DataFrame original\n",
        "data[variables_descripcion] = data[variables_descripcion].replace(mapeo_descripcion)\n"
      ],
      "metadata": {
        "id": "OqWvTuKHbhAR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ruta del archivo donde quieres guardar el DataFrame en Google Drive\n",
        "ruta_guardado = '/content/drive/MyDrive/Bases/BaseGuardada.xlsx'\n",
        "\n",
        "# Guardar el DataFrame en un archivo Excel en la ruta especificada\n",
        "data.to_excel(ruta_guardado, index=False)\n"
      ],
      "metadata": {
        "id": "Txrw1-DSfFuA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ruta del archivo Excel en tu Google Drive\n",
        "ruta_archivo = '/content/drive/MyDrive/Bases/BaseJose2.xlsx'\n",
        "\n",
        "# Cargar el archivo Excel en un DataFrame de Pandas\n",
        "data = pd.read_excel(ruta_archivo)\n",
        "\n",
        "# Mostrar las primeras filas para entender la estructura\n",
        "data.head()"
      ],
      "metadata": {
        "id": "bdL8emPrjpNE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imputación de datos"
      ],
      "metadata": {
        "id": "sK4fvjyodqZZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Método MICE (Multiple Imputation by Chained Equations)\n",
        "\n",
        "El método **MICE (Multiple Imputation by Chained Equations)** es una técnica de imputación de datos utilizada para abordar el problema de valores faltantes en un conjunto de datos. Es un enfoque avanzado y robusto que ofrece varias ventajas para el análisis estadístico. A continuación se presenta una descripción detallada del método:\n",
        "\n",
        "## 1. Imputación Múltiple\n",
        "- **MICE** realiza imputaciones múltiples, creando varios conjuntos completos de datos.\n",
        "- Cada imputación refleja la incertidumbre sobre cómo imputar los valores faltantes.\n",
        "\n",
        "## 2. Proceso Iterativo y Basado en Ecuaciones\n",
        "- El método trabaja de manera iterativa, imputando los valores faltantes uno a uno.\n",
        "- Utiliza ecuaciones encadenadas, donde cada variable con datos faltantes se modela utilizando las demás variables como predictores.\n",
        "\n",
        "## 3. Flexibilidad con Diferentes Tipos de Datos\n",
        "- Es capaz de manejar distintos tipos de variables (continuas, categóricas, binarias, etc.).\n",
        "- Selecciona un modelo estadístico apropiado para la imputación de cada tipo de variable.\n",
        "\n",
        "## 4. Resultados Más Realistas y Robustos\n",
        "- Al crear múltiples imputaciones, MICE proporciona resultados que son más realistas y robustos.\n",
        "- Refleja mejor la incertidumbre inherente en la imputación de valores faltantes.\n",
        "\n",
        "## 5. Análisis de Datos Completo\n",
        "- Se realiza un análisis estadístico en cada conjunto de datos imputado.\n",
        "- Los resultados se combinan para obtener estimaciones finales, considerando la variabilidad dentro y entre los conjuntos imputados.\n",
        "\n",
        "## Algoritmo:  Proceso General\n",
        "\n",
        "1. **Inicialización**: Los valores faltantes se imputan inicialmente con valores provisionales, como la media o la mediana de la variable.\n",
        "\n",
        "   $$ X^{mis}_{init} = f(X^{obs}) $$\n",
        "\n",
        "   Donde $ X^{mis}_{init} $ son los valores faltantes inicialmente imputados y $ X^{obs} $ son los valores observados.\n",
        "\n",
        "2. **Imputación Iterativa**: En cada iteración, cada variable con valores faltantes se imputa secuencialmente. La imputación de una variable específica $ X_j $ en la iteración $ t $ se realiza utilizando un modelo basado en las demás variables.\n",
        "\n",
        "   $$ X_{j}^{(t)} = model(X_{-j}^{(t-1)}, \\theta) + \\epsilon $$\n",
        "\n",
        "   Aquí, $ X_{j}^{(t)} $ es la variable imputada en la iteración $ t $, $ X_{-j}^{(t-1)} $ son las otras variables utilizadas para la imputación, $ \\theta $ son los parámetros del modelo, y $ \\epsilon $ es un término de error.\n",
        "\n",
        "3. **Convergencia**: El proceso se repite hasta que el cambio en las imputaciones entre iteraciones consecutivas es lo suficientemente pequeño, indicando convergencia.\n",
        "\n",
        "## Modelos de Imputación\n",
        "\n",
        "- Los modelos específicos utilizados para $ model(X_{-j}^{(t-1)}, \\theta) $ varían según el tipo de variable (por ejemplo, regresión lineal para variables continuas, regresión logística para variables categóricas).\n",
        "\n",
        "- En cada paso, se ajusta un modelo para la variable con valores faltantes, utilizando las demás variables como predictores.\n",
        "\n",
        "## Resultados\n",
        "\n",
        "- Tras la convergencia, se obtienen múltiples conjuntos de datos imputados, reflejando la incertidumbre en la imputación.\n",
        "\n",
        "- Se realizan análisis estadísticos sobre estos conjuntos, y los resultados se combinan para dar estimaciones finales.\n",
        "\n"
      ],
      "metadata": {
        "id": "L1EtnSW8duZR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.impute import IterativeImputer\n",
        "\n",
        "\n",
        "# Instanciar el imputador iterativo con parámetros adicionales\n",
        "mice_imputer = IterativeImputer(max_iter=10, random_state=0)\n",
        "\n",
        "# Ajustar el imputador a los datos y transformarlos\n",
        "data_imputed = mice_imputer.fit_transform(data)\n",
        "\n",
        "# Redondear los resultados imputados al entero más cercano\n",
        "data_imputed_rounded = pd.DataFrame(data_imputed, columns=data.columns).round(0).astype(int)"
      ],
      "metadata": {
        "id": "Md3T-rJsh0OS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Guardar el DataFrame imputado en un archivo Excel en tu Google Drive\n",
        "data_imputed_rounded.to_excel('/content/drive/MyDrive/Bases/BaseImputada.xlsx', index=False)"
      ],
      "metadata": {
        "id": "kySVPBEJi4r0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Valores nulos\n",
        "valores_nulos = data_imputed_rounded.isnull().sum()\n",
        "valores_nulos"
      ],
      "metadata": {
        "id": "HdSdnmI7HZQi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}