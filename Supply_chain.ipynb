{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bonillahermes/Data_Science_Projects/blob/main/Supply_chain.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hermes Yate Bonilla\n",
        "**Estadístico / Científico de Datos**\n",
        "---\n",
        "\n",
        "**Contacto:**\n",
        "- **Email:** [bonillahermes@gmail.com](mailto:bonillahermes@gmail.com)\n",
        "- **LinkedIn:** [linkedin.com/in/bonillahermes/](https://www.linkedin.com/in/bonillahermes/)\n",
        "- **GitHub:** [github.com/bonillahermes](https://github.com/bonillahermes)\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "LaeZKV-naFzW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Descripción del DataFrame `Sales`\n",
        "\n",
        "El dataframe sales_data contiene información detallada sobre las ventas de diversos materiales (productos) a lo largo de diferentes períodos de tiempo.\n",
        "\n",
        "### Variables:\n",
        "\n",
        "- **Channel**: Esta variable indica el canal de venta a través del cual se realizó la transacción. Es una variable de tipo cadena de texto (object).\n",
        "\n",
        "- **Year.Month**: Esta variable representa el período en el que se realizaron las ventas, utilizando el formato `YYYYMM`. Es una variable de tipo entero (int64) que indica tanto el año como el mes específicos de la venta, proporcionando un marco temporal para el análisis de tendencias y estacionalidades en las ventas.\n",
        "\n",
        "- **Material**: Esta variable es un identificador único del material o producto vendido. Es una variable de tipo entero (int64) que codifica el tipo de producto, permitiendo diferenciar entre los distintos artículos disponibles en el inventario.\n",
        "\n",
        "- **Category**: Esta variable clasifica el material en una categoría específica. Es una cadena de texto (object) que agrupa productos similares o relacionados, facilitando el análisis por segmentos de mercado o líneas de producto.\n",
        "\n",
        "- **Line**: Esta variable representa la línea de producto a la que pertenece el material. Es una cadena de texto (object) que permite una categorización adicional dentro de cada categoría, ayudando a identificar y analizar subgrupos de productos.\n",
        "\n",
        "- **Sales KG**: Esta variable cuantifica el peso total en kilogramos de los materiales vendidos. Es de tipo flotante (float64), proporcionando una medida física de las ventas, lo cual es útil para análisis de logística y manejo de inventario.\n",
        "\n",
        "- **Sales COP**: Esta variable representa los ingresos generados por las ventas del material en pesos colombianos (COP). Es de tipo entero (int64) y refleja el valor monetario total de las ventas en el período especificado por Year.Month."
      ],
      "metadata": {
        "id": "Ync2Fs5XVIRc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Descripción del DataFrame `Stockouts`\n",
        "\n",
        "El dataframe stockouts_data contiene información detallada sobre las faltantes de stock de diversos materiales (productos) a lo largo de diferentes períodos de tiempo.\n",
        "\n",
        "### Variables:\n",
        "\n",
        "- **Year.Month**: Esta variable representa el período en el que ocurrieron las faltantes de stock, utilizando el formato `YYYYMM`. Es una variable de tipo entero (int64) que indica tanto el año como el mes específicos de la falta de stock, proporcionando un marco temporal para el análisis de patrones y estacionalidades en las faltantes.\n",
        "\n",
        "- **Material**: Esta variable es un identificador único del material o producto que tuvo faltantes de stock. Es una variable de tipo entero (int64) que codifica el tipo de producto, permitiendo diferenciar entre los distintos artículos en el inventario.\n",
        "\n",
        "- **Purchase Order KG**: Esta variable cuantifica el peso total en kilogramos de los materiales ordenados en un período específico. Es de tipo entero (int64) y proporciona una medida de la cantidad solicitada al proveedor.\n",
        "\n",
        "- **Purchase Delivered KG**: Esta variable cuantifica el peso total en kilogramos de los materiales entregados en un período específico. Es de tipo entero (int64) y refleja la cantidad realmente recibida del proveedor, lo cual es crucial para identificar discrepancias entre lo ordenado y lo recibido.\n",
        "\n",
        "- **Purchase Pending KG**: Esta variable cuantifica el peso total en kilogramos de los materiales que están pendientes de entrega en un período específico. Es de tipo entero (int64) y proporciona una medida de las órdenes que aún no han sido satisfechas, lo cual es importante para el seguimiento de las faltantes de stock.\n",
        "\n",
        "- **UM**: Esta variable representa la unidad de medida utilizada para los materiales. Es una variable de tipo cadena de texto (object) que indica la unidad en la que se mide el peso o volumen de los materiales, como \"KG\" para kilogramos.\n",
        "\n",
        "- **Fulfillment**: Esta variable representa el porcentaje de cumplimiento de las órdenes de compra, calculado como el ratio entre lo entregado y lo ordenado. Es de tipo flotante (float64) y proporciona una medida del desempeño del proveedor en términos de cumplimiento de órdenes."
      ],
      "metadata": {
        "id": "fCq8N0zFW_mc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preliminares"
      ],
      "metadata": {
        "id": "chivkjaCmd62"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instalación de dependencias y librerías"
      ],
      "metadata": {
        "id": "2rfraTPcELyd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install dash dash-core-components dash-html-components"
      ],
      "metadata": {
        "id": "f66QmdErdyFf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tqdm"
      ],
      "metadata": {
        "id": "1Bg2lgrSHxAP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install xlsxwriter"
      ],
      "metadata": {
        "id": "Q782JavuZ0Pw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras-tuner"
      ],
      "metadata": {
        "id": "LBoilI7bH3Zl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install prophet"
      ],
      "metadata": {
        "id": "v8GOOpxi7Djb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Manejo de datos\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Para descargar datos\n",
        "import requests\n",
        "from io import BytesIO\n",
        "\n",
        "# Visualización de datos\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "import altair as alt\n",
        "\n",
        "# Modelado de series temporales\n",
        "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
        "from statsmodels.tsa.seasonal import seasonal_decompose\n",
        "from statsmodels.tsa.stattools import adfuller\n",
        "from statsmodels.tsa.arima.model import ARIMA\n",
        "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
        "\n",
        "# Modelado y evaluación\n",
        "from prophet import Prophet\n",
        "from sklearn.svm import SVR\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Configuración warnings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Crear todas las combinaciones posibles de hiperparámetros\n",
        "import itertools\n",
        "\n",
        "# Progreso visual\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Evitar advertencias\n",
        "import warnings\n",
        "\n",
        "# Escritura de archivos Excel\n",
        "import xlsxwriter\n",
        "\n",
        "# Modelado con Keras y TensorFlow\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam, RMSprop, SGD\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from keras_tuner import RandomSearch\n",
        "from keras_tuner.engine.hyperparameters import HyperParameters\n",
        "\n",
        "# Creación de dashboard interactivo\n",
        "import dash\n",
        "from dash import dcc, html\n",
        "from dash.dependencies import Input, Output\n",
        "from IPython.display import display, HTML"
      ],
      "metadata": {
        "id": "6FnXCKtNr0dE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tarea de Ingeniería de Datos:"
      ],
      "metadata": {
        "id": "TfoNc8h4pWVP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plan de Trabajo para la Tarea de Ingeniería de Datos\n",
        "\n",
        "### 1. Cargar y limpiar los datos\n",
        "\n",
        "**Objetivo:** Desarrollar scripts para cargar los datos históricos de ventas y faltantes de stock en el cuaderno de notas. Limpiar los datos de inconsistencias, valores faltantes y errores de tipo de datos.\n",
        "\n",
        "**Pasos:**\n",
        "\n",
        "1. **Cargar los datos:**\n",
        "   - Leer el archivo `Assessment.xlsx`.\n",
        "   - Cargar las hojas \"Sales\" y \"Stockouts\" en dataframes separados utilizando pandas.\n",
        "\n",
        "2. **Explorar los datos:**\n",
        "   - Inspeccionar las primeras filas de cada dataframe.\n",
        "   - Obtener información general (tipos de datos, valores faltantes, resumen estadístico).\n",
        "\n",
        "3. **Limpiar los datos:**\n",
        "   - Manejar valores faltantes:\n",
        "     - Identificar columnas con valores faltantes.\n",
        "     - Decidir el enfoque para cada columna (rellenar con media/mediana/moda, eliminar filas, usar imputación avanzada).\n",
        "   - Corregir errores de tipo de datos:\n",
        "     - Convertir columnas a los tipos de datos adecuados (e.g., Year y Month a enteros, Sales y Stockouts a flotantes).\n",
        "   - Eliminar duplicados:\n",
        "     - Identificar y eliminar filas duplicadas.\n",
        "   - Manejar inconsistencias:\n",
        "     - Verificar rangos de valores para detectar inconsistencias (e.g., ventas negativas, meses fuera del rango 1-12).\n",
        "\n",
        "### 2. Combinar los datos de ventas y stockouts\n",
        "\n",
        "**Objetivo:** Combinar los datos de ventas y faltantes de stock basándose en una clave común (por ejemplo, Year.Month, Material) para crear un único conjunto de datos para el análisis de la demanda.\n",
        "\n",
        "**Pasos:**\n",
        "\n",
        "1. **Crear una clave combinada:**\n",
        "   - Crear una nueva columna en ambos dataframes que combine el año y el mes (e.g., `Year.Month`).\n",
        "\n",
        "2. **Unir los datos:**\n",
        "   - Realizar una unión (merge) de los dataframes `sales_data` y `stockouts_data` utilizando las claves comunes `Year.Month` y `Material`.\n",
        "\n",
        "3. **Validar la combinación:**\n",
        "   - Inspeccionar el dataframe combinado para asegurar que la unión se realizó correctamente y que no hay pérdidas de datos importantes.\n",
        "\n",
        "\n",
        "### 3. Derivar nuevas características\n",
        "\n",
        "**Objetivo:** Derivar nuevas características de los datos que podrían ser relevantes para la previsión de la demanda. Por ejemplo, la Tasa de Faltantes y el Porcentaje de órdenes de compra que resultaron en faltantes para cada material.\n",
        "\n",
        "**Pasos:**\n",
        "\n",
        "1. **Calcular la Tasa de Faltantes:**\n",
        "   - Crear una nueva columna `Stockout Rate` calculada como `Stockouts / (Sales + Stockouts)`.\n",
        "\n",
        "\n",
        "2. **Calcular el Porcentaje de Órdenes de Compra con Faltantes:**\n",
        "   - Crear una nueva columna `Purchase Order Percentage` calculada como `(Stockouts / Sales) * 100`.\n",
        "\n",
        "3. **Verificar las nuevas características:**\n",
        "   - Inspeccionar las nuevas columnas para asegurar que los cálculos son correctos y tienen sentido.\n",
        "\n",
        "### 4. Particionar el conjunto de datos\n",
        "\n",
        "**Objetivo:** Dividir el conjunto de datos combinado en datos de entrenamiento (datos históricos) y datos de prueba (un período reciente). Esto se usará para la evaluación del modelo más adelante.\n",
        "\n",
        "**Pasos:**\n",
        "\n",
        "1. **Definir el período de corte:**\n",
        "   - Decidir un umbral temporal para dividir los datos en entrenamiento y prueba (e.g., año 2023).\n",
        "\n",
        "2. **Crear conjuntos de datos de entrenamiento y prueba:**\n",
        "   - Filtrar el dataframe combinado para crear `train_data` con datos históricos.\n",
        "   - Filtrar el dataframe combinado para crear `test_data` con datos recientes.\n",
        "\n",
        "3. **Validar los conjuntos de datos:**\n",
        "   - Inspeccionar los conjuntos de datos `train_data` y `test_data` para asegurar que la partición se realizó correctamente.\n",
        "\n"
      ],
      "metadata": {
        "id": "kSaejtt49ti-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Carga, Limpieza y Tratamiento de Datos"
      ],
      "metadata": {
        "id": "urWeKDsRndpc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cargar Datos"
      ],
      "metadata": {
        "id": "H9GZVwXxACg6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# URL del archivo en GitHub\n",
        "url = 'https://github.com/bonillahermes/Datasets/blob/main/Assessment.xlsx?raw=true'"
      ],
      "metadata": {
        "id": "SqY1NQOHODEY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Descargar el archivo\n",
        "response = requests.get(url)\n",
        "response.raise_for_status()  # Asegura que la solicitud fue exitosa\n",
        "\n",
        "# Leer el archivo Excel en un DataFrame\n",
        "file = BytesIO(response.content)\n",
        "sales_data = pd.read_excel(file, sheet_name='Sales')\n",
        "stockouts_data = pd.read_excel(file, sheet_name='Stockouts')"
      ],
      "metadata": {
        "id": "cD_xFZBVr4BA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mostrar las primeras filas de cada DataFrame\n",
        "print(\"Primeras filas de Sales:\")\n",
        "sales_data.head()"
      ],
      "metadata": {
        "id": "Tnr9VYQi_mEy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nPrimeras filas de Stockouts:\")\n",
        "stockouts_data.head()"
      ],
      "metadata": {
        "id": "J5Qi8UOB_ps3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Explorar Datos"
      ],
      "metadata": {
        "id": "eVe7fsE_AG1h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Información general y valores faltantes en ventas\n",
        "print(\"\\nInformación general de Sales:\")\n",
        "sales_data.info()\n",
        "\n",
        "print(\"\\nValores faltantes en Sales (número y porcentaje):\")\n",
        "missing_values_sales = sales_data.isnull().sum()\n",
        "percent_missing_sales = (sales_data.isnull().sum() / len(sales_data)) * 100\n",
        "missing_sales_summary = pd.DataFrame({'Missing Values': missing_values_sales, 'Percentage': percent_missing_sales})\n",
        "print(missing_sales_summary)"
      ],
      "metadata": {
        "id": "L0ZLSOTJBV7H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Información general y valores faltantes en stockouts\n",
        "print(\"\\nInformación general de Stockouts:\")\n",
        "stockouts_data.info()\n",
        "\n",
        "print(\"\\nValores faltantes en Stockouts (número y porcentaje):\")\n",
        "missing_values_stockouts = stockouts_data.isnull().sum()\n",
        "percent_missing_stockouts = (stockouts_data.isnull().sum() / len(stockouts_data)) * 100\n",
        "missing_stockouts_summary = pd.DataFrame({'Missing Values': missing_values_stockouts, 'Percentage': percent_missing_stockouts})\n",
        "print(missing_stockouts_summary)"
      ],
      "metadata": {
        "id": "2FXI-gPUBq2c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Corregir errores de tipo de datos"
      ],
      "metadata": {
        "id": "Z5_WBKmLenfo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Corregir tipos de datos en sales_data\n",
        "sales_data['Year.Month'] = sales_data['Year.Month'].astype(str)\n",
        "sales_data['Material'] = sales_data['Material'].astype(str)\n",
        "sales_data['Sales KG'] = sales_data['Sales KG'].astype(float)\n",
        "sales_data['Sales COP'] = sales_data['Sales COP'].astype(int)\n",
        "\n",
        "# Verificar cambios\n",
        "print(\"\\nTipos de datos en sales_data después de la corrección:\")\n",
        "print(sales_data.dtypes)"
      ],
      "metadata": {
        "id": "UaBgoqxqfsXL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Corregir tipos de datos en stockouts_data\n",
        "stockouts_data['Year.Month'] = stockouts_data['Year.Month'].astype(str)\n",
        "stockouts_data['Material'] = stockouts_data['Material'].astype(str)\n",
        "stockouts_data['Purchase Order KG'] = stockouts_data['Purchase Order KG'].astype(int)\n",
        "stockouts_data['Purchase Delivered KG'] = stockouts_data['Purchase Delivered KG'].astype(int)\n",
        "stockouts_data['Purchase Pending KG'] = stockouts_data['Purchase Pending KG'].astype(int)\n",
        "stockouts_data['UM'] = stockouts_data['UM'].astype(str)\n",
        "stockouts_data['Fulfillment'] = stockouts_data['Fulfillment'].astype(float)\n",
        "\n",
        "# Verificar cambios\n",
        "print(\"\\nTipos de datos en stockouts_data después de la corrección:\")\n",
        "print(stockouts_data.dtypes)"
      ],
      "metadata": {
        "id": "hsJT0KkEfxRv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tratamiento de Duplicados"
      ],
      "metadata": {
        "id": "YUt4vsCWgme2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Identificar duplicados en sales_data\n",
        "print(\"Duplicados en sales_data antes de la eliminación:\")\n",
        "print(sales_data.duplicated().sum())"
      ],
      "metadata": {
        "id": "MJjEygJJgpTg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Eliminar duplicados en sales_data\n",
        "sales_data = sales_data.drop_duplicates()\n",
        "\n",
        "# Verificar eliminación de duplicados en sales_data\n",
        "print(\"Duplicados en sales_data después de la eliminación:\")\n",
        "print(sales_data.duplicated().sum())"
      ],
      "metadata": {
        "id": "ZJ178Gb3gxa5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Identificar duplicados en stockouts_data\n",
        "print(\"Duplicados en stockouts_data antes de la eliminación:\")\n",
        "print(stockouts_data.duplicated().sum())"
      ],
      "metadata": {
        "id": "9Ztdc96Sg2fw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Eliminar duplicados en stockouts_data\n",
        "stockouts_data = stockouts_data.drop_duplicates()\n",
        "\n",
        "# Verificar eliminación de duplicados en stockouts_data\n",
        "print(\"Duplicados en stockouts_data después de la eliminación:\")\n",
        "print(stockouts_data.duplicated().sum())"
      ],
      "metadata": {
        "id": "elmIB9fRg6zo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tratamiento de Inconsistencias"
      ],
      "metadata": {
        "id": "O729XmfKhwb9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Es necesario verificar que las variables se encuentren en rangos/soportes consistentes."
      ],
      "metadata": {
        "id": "SBBj89BRJBxA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Identificar y corregir inconsistencias en sales_data\n",
        "print(\"Descripción estadística de sales_data antes de la limpieza:\")\n",
        "print(sales_data.describe())"
      ],
      "metadata": {
        "id": "Qp_QYR_YhwDC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filtrar valores inconsistentes en sales_data\n",
        "sales_data = sales_data[(sales_data['Sales KG'] >= 0) & (sales_data['Sales COP'] >= 0)]\n",
        "# Si se conocen rangos específicos para 'Sales KG' y 'Sales COP', se pueden aplicar:\n",
        "# sales_data = sales_data[(sales_data['Sales KG'].between(0, 10000)) & (sales_data['Sales COP'].between(0, 10000000))]\n",
        "# En este caso no tomaré alguna cota superior."
      ],
      "metadata": {
        "id": "GyoTJNspiA45"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Descripción estadística de sales_data después de la limpieza:\")\n",
        "print(sales_data.describe())"
      ],
      "metadata": {
        "id": "94V4B35liOR3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear tablas de frecuencias para las variables categóricas en sales_data\n",
        "print(\"\\nTabla de frecuencias para Channel:\")\n",
        "print(sales_data['Channel'].value_counts())\n",
        "\n",
        "print(\"\\nTabla de frecuencias para Category:\")\n",
        "print(sales_data['Category'].value_counts())\n",
        "\n",
        "print(\"\\nTabla de frecuencias para Line:\")\n",
        "print(sales_data['Line'].value_counts())"
      ],
      "metadata": {
        "id": "AFepR0iCj-lR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Con lo anterior, se observa que existen variables con una única instancia/categoría, lo cual no aporta información a los modelos, pero nos ayuda en temas logísticos. Más adelante para el modelado estas variables no serán tomadas en cuenta. A continuación, como parte de la limpeza de datos, revisamos carácteres extraños o inconsistentes en las variables."
      ],
      "metadata": {
        "id": "FBS5ABkqIGjm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Detectar caracteres extraños en Year.Month y Material en sales_data\n",
        "print(\"\\nObservaciones con caracteres extraños en Year.Month en sales_data:\")\n",
        "print(sales_data[~sales_data['Year.Month'].str.match(r'^\\d{6}$')])\n",
        "\n",
        "print(\"\\nObservaciones con caracteres extraños en Material en sales_data:\")\n",
        "print(sales_data[~sales_data['Material'].str.match(r'^\\d+$')])"
      ],
      "metadata": {
        "id": "f7tSt6P1lXos"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear boxplots para las variables numéricas en sales_data\n",
        "numeric_columns_sales = ['Sales KG', 'Sales COP']\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "for i, column in enumerate(numeric_columns_sales, 1):\n",
        "    plt.subplot(1, len(numeric_columns_sales), i)\n",
        "    sns.boxplot(y=sales_data[column])\n",
        "    plt.title(f'Boxplot de {column}')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "DRC4m5QTmS1_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Los gráficos boxplot de las variables Sales KG y Sales COP muestran una distribución altamente sesgada con numerosos valores atípicos, lo que indica fluctuaciones significativas en las ventas tanto en kilogramos como en pesos colombianos. La presencia de estos valores atípicos sugiere posibles eventos inusuales o picos de demanda que podrían estar influenciados por factores externos como campañas de marketing, variaciones estacionales o cambios en las políticas gubernamentales. Para el modelado, estos valores atípicos pueden sesgar los resultados y afectar la precisión de las predicciones, por lo que es crucial considerarlos en el preprocesamiento de datos y, si es necesario, ajustar el modelo para manejar estas anomalías adecuadamente."
      ],
      "metadata": {
        "id": "gdvUTBtPJ6q2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Identificar y corregir inconsistencias en stockouts_data\n",
        "print(\"Descripción estadística de stockouts_data antes de la limpieza:\")\n",
        "print(stockouts_data.describe())"
      ],
      "metadata": {
        "id": "ViV_xHVEjAi8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filtrar valores inconsistentes en stockouts_data\n",
        "stockouts_data = stockouts_data[(stockouts_data['Purchase Order KG'] >= 0) &\n",
        "                                (stockouts_data['Purchase Delivered KG'] >= 0) &\n",
        "                                (stockouts_data['Purchase Pending KG'] >= 0) &\n",
        "                                (stockouts_data['Fulfillment'].between(0, 100))]"
      ],
      "metadata": {
        "id": "ONcDS5hUjH8j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Descripción estadística de stockouts_data después de la limpieza:\")\n",
        "print(stockouts_data.describe())"
      ],
      "metadata": {
        "id": "uiVyJPAjjMVm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear tablas de frecuencias para las variables categóricas en stockouts_data\n",
        "print(\"\\nTabla de frecuencias para UM:\")\n",
        "print(stockouts_data['UM'].value_counts())"
      ],
      "metadata": {
        "id": "QyzMZ6GqlDy8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Esta variable solo presenta una única categoría"
      ],
      "metadata": {
        "id": "chxPr9B5KB2S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Detectar caracteres extraños en Year.Month y Material en stockouts_data\n",
        "print(\"\\nObservaciones con caracteres extraños en Year.Month en stockouts_data:\")\n",
        "print(stockouts_data[~stockouts_data['Year.Month'].str.match(r'^\\d{6}$')])\n",
        "\n",
        "print(\"\\nObservaciones con caracteres extraños en Material en stockouts_data:\")\n",
        "print(stockouts_data[~stockouts_data['Material'].str.match(r'^\\d+$')])"
      ],
      "metadata": {
        "id": "4WdkWd4ylUh4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear boxplots para las variables numéricas en stockouts_data\n",
        "numeric_columns_stockouts = ['Purchase Order KG', 'Purchase Delivered KG', 'Purchase Pending KG', 'Fulfillment']\n",
        "\n",
        "plt.figure(figsize=(16, 8))\n",
        "for i, column in enumerate(numeric_columns_stockouts, 1):\n",
        "    plt.subplot(1, len(numeric_columns_stockouts), i)\n",
        "    sns.boxplot(y=stockouts_data[column])\n",
        "    plt.title(f'Boxplot de {column}')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "VausBvbsmdGn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Los gráficos boxplot de las variables Purchase Order KG, Purchase Delivered KG, Purchase Pending KG y Fulfillment muestran una distribución con numerosos valores atípicos. En particular, Purchase Order KG, Purchase Delivered KG y Purchase Pending KG presentan un rango de valores muy amplio, indicando pedidos y entregas que varían significativamente en tamaño. Estos valores atípicos pueden indicar eventos de compra extraordinarios o problemas en la cadena de suministro. Por otro lado, el boxplot de Fulfillment muestra que la mayoría de los valores se concentran en un rango más estrecho, sugiriendo un nivel de cumplimiento más consistente, aunque todavía con variabilidad significativa. Estos hallazgos resaltan la importancia de considerar estos valores atípicos en el análisis y modelado para evitar que sesguen los resultados y mejorar la precisión de las predicciones."
      ],
      "metadata": {
        "id": "FtZ_DapeKnqI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Combinar los datos de ventas y stockouts"
      ],
      "metadata": {
        "id": "vyaWDdRJntzZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear la variable ID en ambos dataframes\n",
        "sales_data['ID'] = sales_data['Year.Month'] + '-' + sales_data['Material']\n",
        "stockouts_data['ID'] = stockouts_data['Year.Month'] + '-' + stockouts_data['Material']\n",
        "\n",
        "# Verificar las primeras filas para asegurarse de que la variable ID se ha creado correctamente\n",
        "print(\"Primeras filas de sales_data con ID:\")\n",
        "print(sales_data.head())\n",
        "\n",
        "print(\"\\nPrimeras filas de stockouts_data con ID:\")\n",
        "print(stockouts_data.head())"
      ],
      "metadata": {
        "id": "bidJmVRQn5q4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Realizar la unión de los dataframes basados en la variable ID\n",
        "combined_data = pd.merge(sales_data, stockouts_data, on='ID', how='inner', suffixes=('_sales', '_stockouts'))\n",
        "\n",
        "# Mostrar las primeras filas del dataframe combinado\n",
        "print(\"\\nPrimeras filas del dataframe combinado:\")\n",
        "combined_data.head()"
      ],
      "metadata": {
        "id": "ln0qlakvpiZP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Eliminar las columnas duplicadas de Year.Month y Material de stockouts_data\n",
        "combined_data.drop(columns=['Year.Month_stockouts', 'Material_stockouts'], inplace=True)\n",
        "\n",
        "# Renombrar las columnas de sales_data para quitar los sufijos\n",
        "combined_data.rename(columns={'Year.Month_sales': 'Year.Month', 'Material_sales': 'Material'}, inplace=True)\n",
        "\n",
        "# Mostrar las primeras filas del dataframe combinado\n",
        "print(\"\\nPrimeras filas del dataframe combinado:\")\n",
        "combined_data.head()"
      ],
      "metadata": {
        "id": "asb-s8y9rEEm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Información general del dataframe combinado\n",
        "print(\"\\nInformación general del dataframe combinado:\")\n",
        "print(combined_data.info())"
      ],
      "metadata": {
        "id": "rnBH6e--p0PV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convertir Year.Month a datetime\n",
        "combined_data['Year.Month'] = pd.to_datetime(combined_data['Year.Month'], format='%Y%m')\n",
        "\n",
        "# Verificar el cambio\n",
        "print(combined_data.info())\n",
        "combined_data['Year.Month'].head()"
      ],
      "metadata": {
        "id": "8umLJgrDHRmW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Derivar Nuevas Características"
      ],
      "metadata": {
        "id": "tnw2sjrquIhs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Descripción de las Nuevas Variables Derivadas en `combined_data`\n",
        "\n",
        "Para mejorar la cadena de suministro, es fundamental tener una comprensión clara de la eficiencia y efectividad del proceso de entrega de productos. Las nuevas variables derivadas ayudan a identificar áreas problemáticas y oportunidades para optimizar el flujo de bienes desde el proveedor hasta el cliente final.\n",
        "\n",
        "#### 1. Stockout Rate (Tasa de Faltantes de Stock)\n",
        "\n",
        "**Descripción:**\n",
        "\n",
        "La `Stockout Rate` mide el porcentaje de la orden de compra que no fue entregada en un período específico. Se calcula como:\n",
        "$$ \\text{Stockout Rate} = \\left( \\frac{\\text{Purchase Order KG} - \\text{Purchase Delivered KG}}{\\text{Purchase Order KG}} \\right) \\times 100 $$\n",
        "\n",
        "**Justificación:**\n",
        "\n",
        "Esta variable es crucial para identificar la frecuencia y severidad de los faltantes de stock. Un alto `Stockout Rate` indica problemas en la disponibilidad de inventario, lo que puede llevar a pérdidas de ventas y disminución de la satisfacción del cliente. Al monitorear esta métrica, las empresas pueden tomar medidas proactivas para mejorar la planificación del inventario y reducir las interrupciones en el suministro.\n",
        "\n",
        "#### 2. Fulfillment Rate (Tasa de Cumplimiento de la Orden de Compra)\n",
        "\n",
        "**Descripción:**\n",
        "\n",
        "La `Fulfillment Rate` mide el porcentaje de la orden de compra que fue entregada en un período específico. Se calcula como:\n",
        "$$ \\text{Fulfillment Rate} = \\left( \\frac{\\text{Purchase Delivered KG}}{\\text{Purchase Order KG}} \\right) \\times 100 $$\n",
        "\n",
        "**Justificación:**\n",
        "Esta variable proporciona una medida directa del desempeño del proveedor en términos de cumplimiento de órdenes. Un alto `Fulfillment Rate` indica que la mayoría de las órdenes se entregan según lo planeado, lo cual es vital para mantener una cadena de suministro eficiente y confiable. Monitorear esta métrica permite a las empresas evaluar la efectividad de sus proveedores y mejorar la gestión de relaciones con ellos.\n",
        "\n",
        "\n",
        "#### 3. Pending Order Rate (Tasa de Órdenes Pendientes)\n",
        "\n",
        "**Descripción:**\n",
        "\n",
        "La `Pending Order Rate` mide el porcentaje de la orden de compra que aún no se ha entregado en un período específico. Se calcula como:\n",
        "$$ \\text{Pending Order Rate} = \\left( \\frac{\\text{Purchase Pending KG}}{\\text{Purchase Order KG}} \\right) \\times 100 $$\n",
        "\n",
        "**Justificación:**\n",
        "\n",
        "Esta variable es útil para identificar retrasos en la entrega y entender mejor la eficiencia de la cadena de suministro. Un alto `Pending Order Rate` puede indicar problemas en la capacidad del proveedor para cumplir con las órdenes a tiempo, lo que puede afectar la disponibilidad del producto y la satisfacción del cliente. Analizar esta métrica ayuda a detectar cuellos de botella y mejorar la coordinación con los proveedores.\n",
        "\n",
        "\n",
        "### Conclusión\n",
        "\n",
        "Las variables derivadas `Stockout Rate`, `Fulfillment Rate`, y `Pending Order Rate` proporcionan insights valiosos sobre la eficiencia y efectividad de la cadena de suministro. Al monitorear y analizar estas métricas, las empresas pueden:\n",
        "\n",
        "1. **Reducir Faltantes de Stock:** Identificar y abordar las causas de los faltantes de stock, mejorando la disponibilidad del producto y la satisfacción del cliente.\n",
        "2. **Mejorar el Desempeño del Proveedor:** Evaluar la capacidad de los proveedores para cumplir con las órdenes a tiempo, optimizando la gestión de relaciones con los proveedores y asegurando un suministro confiable.\n",
        "3. **Identificar Retrasos:** Detectar y solucionar problemas de entrega pendientes, facilitando una mejor planificación y coordinación en la cadena de suministro.\n",
        "\n",
        "Implementar estas métricas ayuda a las empresas a tomar decisiones informadas y estratégicas para mejorar la eficiencia operativa y optimizar su cadena de suministro.\n"
      ],
      "metadata": {
        "id": "xAucmfa3vv4o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Derivar nuevas características\n",
        "\n",
        "# Tasa de faltantes de stock: porcentaje de la orden de compra que no fue entregada\n",
        "combined_data['Stockout Rate'] = ((combined_data['Purchase Order KG'] - combined_data['Purchase Delivered KG']) / combined_data['Purchase Order KG']) * 100\n",
        "\n",
        "# Tasa de cumplimiento de la orden de compra: porcentaje de la orden de compra que fue entregada\n",
        "combined_data['Fulfillment Rate'] = (combined_data['Purchase Delivered KG'] / combined_data['Purchase Order KG']) * 100\n",
        "\n",
        "# Tasa de órdenes pendientes: porcentaje de la orden de compra que aún no se ha entregado\n",
        "combined_data['Pending Order Rate'] = (combined_data['Purchase Pending KG'] / combined_data['Purchase Order KG']) * 100"
      ],
      "metadata": {
        "id": "sxIk1qRsuNZK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Verificar las nuevas características\n",
        "print(\"\\nNuevas características derivadas:\")\n",
        "combined_data[['ID', 'Stockout Rate', 'Fulfillment Rate', 'Pending Order Rate']].head()"
      ],
      "metadata": {
        "id": "EIXjc3KcuUkb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Descripción estadística de las nuevas características\n",
        "print(\"\\nDescripción estadística de las nuevas características:\")\n",
        "print(combined_data[['Stockout Rate', 'Fulfillment Rate', 'Pending Order Rate']].describe())"
      ],
      "metadata": {
        "id": "vphjsqW7uWry"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear un DataFrame para facilitar la visualización conjunta\n",
        "melted_data = combined_data.melt(value_vars=['Stockout Rate', 'Fulfillment Rate', 'Pending Order Rate'],\n",
        "                                 var_name='Metric', value_name='Value')\n",
        "\n",
        "# Crear el boxplot\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.boxplot(x='Metric', y='Value', data=melted_data)\n",
        "plt.title('Boxplots de Stockout Rate, Fulfillment Rate y Pending Order Rate')\n",
        "plt.xlabel('Metric')\n",
        "plt.ylabel('Rate (%)')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "AolbrjITywD5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Los estadísticos descriptivos de las nuevas características revelan problemas que requieren especial atención en la cadena de suministro. La alta media y mediana de las tasas de faltantes de stock (75.27% y 87.50%, respectivamente) y de órdenes pendientes (75.27% y 87.50%) indican una gran proporción de órdenes de compra que no se entregan o permanecen pendientes. Además, la baja media y mediana de la tasa de cumplimiento (24.73% y 12.50%) sugieren que los proveedores no están cumpliendo eficientemente con las órdenes de compra.\n",
        "\n",
        "La alta desviación estándar en todas las métricas indica una gran variabilidad, lo que resalta la necesidad de mejorar la consistencia y la eficiencia en la cadena de suministro. Estas métricas proporcionan insights críticos que pueden ayudar a las empresas a identificar áreas problemáticas y a implementar estrategias para optimizar la disponibilidad de inventario y la entrega oportuna de productos."
      ],
      "metadata": {
        "id": "CJMZq7Jax1fR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Agrupar por 'Line' y calcular los estadísticos descriptivos para cada métrica\n",
        "grouped_stats1 = combined_data.groupby('Line').agg(\n",
        "    Stockout_Rate_Mean=('Stockout Rate', 'mean'),\n",
        "    Stockout_Rate_Std=('Stockout Rate', 'std'),\n",
        "    Stockout_Rate_Median=('Stockout Rate', 'median'),\n",
        ").reset_index()\n",
        "\n",
        "# Mostrar la tabla de estadísticos descriptivos por 'Line'\n",
        "grouped_stats1"
      ],
      "metadata": {
        "id": "ViNIDdKt04Xc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "En el análisis de la Tasa de Faltantes (Stockout Rate) por línea de producto, se identificaron productos con altas tasas de faltantes, como Licor de Cacao Industrial (100%) y Toppings (93.23%), sugiriendo problemas significativos de disponibilidad. La alta variabilidad y valores extremos en ciertas líneas, como Chocolate Real y Coberturas y Chips Industriales, indican la necesidad de mejorar la gestión de inventario y la planificación de la producción."
      ],
      "metadata": {
        "id": "P-mY-VJdLtKq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Agrupar por 'Line' y calcular los estadísticos descriptivos para cada métrica\n",
        "grouped_stats2 = combined_data.groupby('Line').agg(\n",
        "    Fulfillment_Rate_Mean=('Fulfillment Rate', 'mean'),\n",
        "    Fulfillment_Rate_Std=('Fulfillment Rate', 'std'),\n",
        "    Fulfillment_Rate_Median=('Fulfillment Rate', 'median'),\n",
        ").reset_index()\n",
        "\n",
        "# Mostrar la tabla de estadísticos descriptivos por 'Line'\n",
        "grouped_stats2"
      ],
      "metadata": {
        "id": "xbnUE3M23D5u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "El análisis de la Tasa de Cumplimiento (Fulfillment Rate) por línea de producto revela problemas de especial atención en la capacidad de cumplir con los pedidos, especialmente en productos como Licor de Cacao Industrial (0%) y Toppings (6.77%). La baja tasa de cumplimiento y alta variabilidad en líneas como Chocolate Real y Coberturas y Chips Industriales sugieren la necesidad de mejorar la gestión de inventario y la eficiencia en la cadena de suministro. Estos hallazgos destacan la importancia de abordar tanto los valores atípicos como los factores externos que influyen en la demanda y la disponibilidad de productos para optimizar la planificación y la previsión en la empresa."
      ],
      "metadata": {
        "id": "AeMFdkQzMHo1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Agrupar por 'Line' y calcular los estadísticos descriptivos para cada métrica\n",
        "grouped_stats3 = combined_data.groupby('Line').agg(\n",
        "    Pending_Order_Rate_Mean=('Pending Order Rate', 'mean'),\n",
        "    Pending_Order_Rate_Std=('Pending Order Rate', 'std'),\n",
        "    Pending_Order_Rate_Median=('Pending Order Rate', 'median'),\n",
        ").reset_index()\n",
        "\n",
        "# Mostrar la tabla de estadísticos descriptivos por 'Line'\n",
        "grouped_stats3"
      ],
      "metadata": {
        "id": "EVti91Qc3LHW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "El análisis de la Tasa de Pedidos Pendientes (Pending Order Rate) muestra altos niveles de pedidos no cumplidos, especialmente en Licor de Cacao Industrial y Toppings, ambos con una tasa media cercana al 100%. Estos altos valores y la baja variabilidad en algunos productos indican problemas consistentes en el cumplimiento de pedidos. La variabilidad es alta en líneas como Chocolate Real y Coberturas y Chips Industriales, lo que sugiere una gestión de inventarios inconsistente. Abordar estos problemas mejorará la precisión de las previsiones y la satisfacción del cliente, asegurando una cadena de suministro más eficiente y confiable."
      ],
      "metadata": {
        "id": "3o8NcZWAMwjR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Particionar el Conjunto de Datos"
      ],
      "metadata": {
        "id": "X4YWxh6MUCYa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Asegurarse de que Year.Month esté ordenado\n",
        "combined_data = combined_data.sort_values(by='Year.Month')\n",
        "\n",
        "# Determinar el punto de división\n",
        "train_size = int(len(combined_data) * 0.8)\n",
        "\n",
        "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
        "train_data = combined_data.iloc[:train_size]\n",
        "test_data = combined_data.iloc[train_size:]"
      ],
      "metadata": {
        "id": "2hfUJMTsUCBB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Verificar la partición\n",
        "print(\"Datos de entrenamiento:\")\n",
        "train_data.head()"
      ],
      "metadata": {
        "id": "3oUaHMMNWNkH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Verificar la partición\n",
        "print(\"Datos de entrenamiento:\")\n",
        "train_data.tail()"
      ],
      "metadata": {
        "id": "pLCxZPHoWOzn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nDatos de prueba:\")\n",
        "test_data.head()"
      ],
      "metadata": {
        "id": "RmNH4AnQVuI5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nDatos de prueba:\")\n",
        "test_data.tail()"
      ],
      "metadata": {
        "id": "FTHoLoV4V3_O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ruta del archivo donde se guardará combined_data\n",
        "file_path = \"/content/combined_data.xlsx\"\n",
        "\n",
        "# Guardar el dataframe en un archivo Excel\n",
        "combined_data.to_excel(file_path, index=False, engine='xlsxwriter')\n"
      ],
      "metadata": {
        "id": "5kr5LpqiZN_A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tareas de Ciencia de Datos:"
      ],
      "metadata": {
        "id": "gXmbK-cKpZOz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plan de Trabajo para las Tareas de Científico de Datos\n",
        "\n",
        "### Paso 1: Visualización de Datos\n",
        "#### Visualización de la Demanda Mensual:\n",
        "- Crear gráficos de línea de la demanda mensual (Sales KG) para identificar tendencias y estacionalidad.\n",
        "- Utilizar gráficos de caja (boxplots) para detectar posibles valores atípicos.\n",
        "\n",
        "#### Análisis de Patrones de Faltantes de Stock:\n",
        "- Visualizar la Stockout Rate a lo largo del tiempo para identificar patrones y estacionalidad.\n",
        "- Analizar la correlación entre Stockout Rate y Sales KG para entender su impacto en la demanda.\n",
        "\n",
        "### Paso 2: Selección y Justificación del Modelo\n",
        "#### Análisis de las Características de los Datos:\n",
        "- Evaluar la naturaleza de los datos (series temporales, no lineales, etc.).\n",
        "- Considerar modelos de series temporales como ARIMA para capturar tendencias y estacionalidad.\n",
        "- Evaluar modelos de aprendizaje automático como Random Forest para capturar relaciones no lineales.\n",
        "\n",
        "#### Justificación del Modelo:\n",
        "- Seleccionar un modelo basado en las características identificadas.\n",
        "- Justificar la elección del modelo con base en su capacidad para manejar las características de los datos y la naturaleza del problema.\n",
        "\n",
        "### Paso 3: Entrenamiento del Modelo\n",
        "#### Preparación de los Datos:\n",
        "- Dividir los datos en conjuntos de entrenamiento y prueba (hecho anteriormente).\n",
        "Incorporar las características derivadas durante las tareas de ingeniería de datos.\n",
        "\n",
        "#### Entrenamiento del Modelo:\n",
        "- Entrenar el modelo seleccionado con los datos históricos de demanda.\n",
        "- Explorar el ajuste de hiperparámetros para optimizar el rendimiento del modelo.\n",
        "\n",
        "### Paso 4: Evaluación del Modelo\n",
        "#### Evaluación del Rendimiento del Modelo:\n",
        "- Utilizar métricas como el Error Cuadrático Medio (MSE) y el Error Porcentual Absoluto Medio (MAPE) para evaluar el rendimiento del modelo en los datos de prueba.\n",
        "- Analizar los resultados para identificar posibles debilidades y áreas de mejora.\n",
        "\n",
        "### Paso 5: Generación de Pronósticos\n",
        "#### Generación de Pronósticos:\n",
        "- Utilizar el modelo entrenado para generar pronósticos para los próximos 6 meses para cada material.\n",
        "- Visualizar los pronósticos junto con los datos históricos para verificar la coherencia y precisión de las predicciones."
      ],
      "metadata": {
        "id": "Nz__atwJYvt9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualización de Datos"
      ],
      "metadata": {
        "id": "kEeksF1TbJ1M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Justificación de la Selección de la Variable Objetivo\n",
        "La variable Sales KG fue elegida como la variable objetivo para el análisis debido a su consistencia y comparabilidad. Representa una medida de volumen constante en el tiempo, no sujeta a fluctuaciones económicas como la inflación o variaciones en los precios. Esto la hace una métrica más confiable para analizar tendencias y patrones históricos. Además, Sales KG proporciona una visión neutral del rendimiento de ventas sin la interferencia de factores económicos externos.\n",
        "\n",
        "Desde una perspectiva operativa, Sales KG es fundamental para la planificación y gestión de la cadena de suministro y la logística, ya que las decisiones sobre producción, inventario y distribución se basan en el volumen de producto vendido. Permite un análisis claro de las tendencias y patrones estacionales, facilitando la identificación de picos de demanda y períodos de baja actividad. Para la empresa, entender y predecir Sales KG tiene un impacto directo en la capacidad de satisfacer la demanda del mercado y optimizar los niveles de inventario, reduciendo los costos asociados a los faltantes de stock y el exceso de inventario."
      ],
      "metadata": {
        "id": "6dj8tDOaQLDA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# URL de inserción de Power BI\n",
        "power_bi_embed_url = \"https://app.powerbi.com/reportEmbed?reportId=4dace1a2-3ca4-4755-b0e7-4c89c29ef0f6&autoAuth=true&ctid=577fc1d8-0922-458e-87bf-ec4f455eb600\"\n",
        "\n",
        "# Crear el HTML para incrustar el informe\n",
        "html_code = f\"\"\"\n",
        "    <iframe\n",
        "        width=\"100%\"\n",
        "        height=\"600\"\n",
        "        src=\"{power_bi_embed_url}\"\n",
        "        frameborder=\"0\"\n",
        "        allowFullScreen=\"true\"></iframe>\n",
        "    \"\"\"\n",
        "\n",
        "# Mostrar el informe incrustado\n",
        "display(HTML(html_code))\n"
      ],
      "metadata": {
        "id": "3k8DnZ6aevdA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adicionalmente:"
      ],
      "metadata": {
        "id": "UzUfXAx2heOC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear una nueva columna 'Month' para el boxplot\n",
        "combined_data['Month'] = combined_data['Year.Month'].dt.strftime('%Y-%m')\n",
        "\n",
        "# Configurar el tamaño de la figura\n",
        "plt.figure(figsize=(14, 7))\n",
        "\n",
        "# Crear el boxplot para Sales KG\n",
        "sns.boxplot(x='Month', y='Sales KG', data=combined_data)\n",
        "\n",
        "# Ajustar etiquetas y título\n",
        "plt.xticks(rotation=45)\n",
        "plt.xlabel('Mes')\n",
        "plt.ylabel('Sales KG')\n",
        "plt.title('Boxplot de Sales KG por Mes')\n",
        "\n",
        "# Mostrar el gráfico\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3_272QWohggL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Configurar el tamaño de la figura\n",
        "plt.figure(figsize=(14, 7))\n",
        "\n",
        "# Crear el boxplot para Stockout Rate\n",
        "sns.boxplot(x='Month', y='Stockout Rate', data=combined_data)\n",
        "\n",
        "# Ajustar etiquetas y título\n",
        "plt.xticks(rotation=45)\n",
        "plt.xlabel('Mes')\n",
        "plt.ylabel('Stockout Rate (%)')\n",
        "plt.title('Boxplot de Stockout Rate por Mes')\n",
        "\n",
        "# Mostrar el gráfico\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "WPQpgx0ziRz_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Selección y Justificación del Modelo"
      ],
      "metadata": {
        "id": "HSKiZXxRkCRi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Realizar la unión de los dataframes basados en la variable ID\n",
        "combined_data = pd.merge(sales_data, stockouts_data, on='ID', how='inner', suffixes=('_sales', '_stockouts'))\n",
        "\n",
        "# Eliminar las columnas duplicadas de Year.Month y Material de stockouts_data\n",
        "combined_data.drop(columns=['Year.Month_stockouts', 'Material_stockouts'], inplace=True)\n",
        "\n",
        "# Renombrar las columnas de sales_data para quitar los sufijos\n",
        "combined_data.rename(columns={'Year.Month_sales': 'Year.Month', 'Material_sales': 'Material'}, inplace=True)\n",
        "\n",
        "# Convertir Year.Month a datetime\n",
        "combined_data['Year.Month'] = pd.to_datetime(combined_data['Year.Month'], format='%Y%m')\n",
        "\n",
        "# Eliminar las variables Channel, Category y UM\n",
        "combined_data = combined_data.drop(columns=['Channel', 'Category', 'UM'])\n",
        "\n",
        "# Tasa de faltantes de stock: porcentaje de la orden de compra que no fue entregada\n",
        "combined_data['Stockout Rate'] = ((combined_data['Purchase Order KG'] - combined_data['Purchase Delivered KG']) / combined_data['Purchase Order KG']) * 100\n",
        "\n",
        "# Tasa de cumplimiento de la orden de compra: porcentaje de la orden de compra que fue entregada\n",
        "combined_data['Fulfillment Rate'] = (combined_data['Purchase Delivered KG'] / combined_data['Purchase Order KG']) * 100\n",
        "\n",
        "# Tasa de órdenes pendientes: porcentaje de la orden de compra que aún no se ha entregado\n",
        "combined_data['Pending Order Rate'] = (combined_data['Purchase Pending KG'] / combined_data['Purchase Order KG']) * 100\n",
        "\n",
        "combined_data.head()"
      ],
      "metadata": {
        "id": "N1yYBOhmptl3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 0. Limpieza de la variable Sales KG\n"
      ],
      "metadata": {
        "id": "ASYcossgtb3e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcular los cuartiles\n",
        "Q1 = combined_data['Sales KG'].quantile(0.25)\n",
        "Q3 = combined_data['Sales KG'].quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "\n",
        "# Definir los límites inferior y superior para identificar valores atípicos\n",
        "lower_bound = Q1 - 1.5 * IQR\n",
        "upper_bound = Q3 + 1.5 * IQR\n",
        "\n",
        "# Identificar valores atípicos\n",
        "outliers = combined_data[(combined_data['Sales KG'] < lower_bound) | (combined_data['Sales KG'] > upper_bound)]\n",
        "print(\"Valores atípicos identificados:\")\n",
        "print(outliers)\n"
      ],
      "metadata": {
        "id": "xuL79HBjthao"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Eliminar los valores atípicos\n",
        "combined_data = combined_data[(combined_data['Sales KG'] >= lower_bound) & (combined_data['Sales KG'] <= upper_bound)]\n",
        "print(\"Datos después de eliminar valores atípicos:\")\n",
        "print(combined_data.head())\n"
      ],
      "metadata": {
        "id": "n7tL-TrhtnL2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Visualización de la Serie Temporal\n",
        "Primero, visualizamos la serie temporal de Sales KG para observar cualquier tendencia o estacionalidad."
      ],
      "metadata": {
        "id": "HxLBr67rkKOp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Graficar la serie temporal\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(combined_data['Sales KG'])\n",
        "plt.xlabel('Fecha')\n",
        "plt.ylabel('Sales KG')\n",
        "plt.title('Demanda Mensual (Sales KG)')\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "bp9pT9ZmkDDm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Descomposición de la Serie Temporal\n",
        "Descomponemos la serie temporal para observar sus componentes: tendencia, estacionalidad y residuales."
      ],
      "metadata": {
        "id": "sX_H9KJ1mHPd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Descomponer la serie temporal\n",
        "decomposition = seasonal_decompose(combined_data['Sales KG'], model='additive', period=12)\n",
        "decomposition.plot()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "FmSFTjRMmNfI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Análisis del Gráfico de Tendencia:**\n",
        " * Tendencia (Trend):\n",
        "  En el gráfico de tendencia, parece que hay fluctuaciones notables con algunos picos y valles.\n",
        "  No hay una tendencia claramente ascendente o descendente sostenida a lo largo del tiempo.\n",
        "  Los picos en la tendencia indican períodos en los que las ventas fueron significativamente mayores, mientras que los valles indican períodos de ventas más bajas.\n",
        "\n",
        "* La serie temporal muestra fluctuaciones considerables en la tendencia, lo que sugiere que hay factores que influyen significativamente en ciertos períodos.\n",
        "\n",
        "- Identificación de Picos:\n",
        " * Los picos en la tendencia podrían estar asociados con eventos específicos, promociones, o factores estacionales que aumentan significativamente las ventas.\n",
        "\n",
        "\n",
        "**Componente Estacional:**\n",
        "\n",
        "- La estacionalidad captura patrones recurrentes a lo largo de un período específico (por ejemplo, mensual, trimestral, anual). Esto es útil para entender patrones que se repiten regularmente.\n",
        "\n",
        "- El componente estacional parece tener un patrón claramente repetitivo, lo cual es un indicativo de estacionalidad en los datos de ventas.\n",
        "Estos ciclos podrían representar fluctuaciones mensuales, por ejemplo, picos en ciertos meses del año debido a estacionalidades conocidas (festividades, promociones anuales, etc.).\n",
        "\n",
        "**Componente de Residuos:**\n",
        "\n",
        "- Los residuos representan las fluctuaciones aleatorias que no se explican por la tendencia ni por la estacionalidad. Es importante revisar si los residuos se comportan como ruido blanco, es decir, si son distribuidos aleatoriamente sin patrones claros.\n",
        "\n",
        "- Los residuos muestran puntos dispersos alrededor de la línea base (cero), con algunos picos notables.\n",
        "La presencia de estos picos podría indicar eventos o anomalías específicas no capturadas por los componentes de tendencia y estacionalidad."
      ],
      "metadata": {
        "id": "m9Hfl9CZoYUw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Prueba de Estacionaridad\n",
        "Realizamos la prueba de Dickey-Fuller aumentada (ADF) para verificar la estacionaridad de la serie temporal."
      ],
      "metadata": {
        "id": "dLrMoiypmxbm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prueba de Dickey-Fuller aumentada\n",
        "result = adfuller(combined_data['Sales KG'])\n",
        "print('ADF Statistic:', result[0])\n",
        "print('p-value:', result[1])\n",
        "for key, value in result[4].items():\n",
        "    print(f'Critical Value ({key}): {value}')\n"
      ],
      "metadata": {
        "id": "1FHuRrLimwig"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dado que el valor del estadístico ADF (-12.185707814694213) es menor que los valores críticos para todos los niveles de significancia (1%, 5%, y 10%), y el p-valor es extremadamente pequeño, podemos concluir que la serie Sales KG es estacionaria."
      ],
      "metadata": {
        "id": "Mzud_4-gnObM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Análisis de ACF y PACF\n",
        "Graficamos las funciones de autocorrelación (ACF) y autocorrelación parcial (PACF) para identificar los posibles valores de los parámetros p, d, q del modelo ARIMA."
      ],
      "metadata": {
        "id": "N4xVKGqyp9ik"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Graficar ACF y PACF para la serie original ya que es estacionaria\n",
        "plt.figure(figsize=(12, 6))\n",
        "plot_acf(combined_data['Sales KG'], lags=24)\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "plot_pacf(combined_data['Sales KG'], lags=24)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "P9ufofPop_l_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dado que la serie temporal de Sales KG es estacionaria y analizando los gráficos de ACF y PACF, se pueden considerar las siguientes opciones de modelado:\n",
        "\n",
        "- Modelo AR(1):\n",
        "  * En el gráfico PACF, hay un corte significativo después del primer rezago (lag), lo que sugiere que un modelo autoregresivo de primer orden podría ser adecuado.\n",
        "  * El modelo sería ARIMA(1, 0, 0) para capturar la autoregresión de primer orden.\n",
        "\n",
        "- Modelo MA(1):\n",
        "  * En el gráfico ACF, se observa un decaimiento gradual, pero significativo, después del primer rezago (lag), lo que indica que un modelo de media móvil de primer orden también podría ser apropiado.\n",
        "  * El modelo sería ARIMA(0, 0, 1) para capturar el componente de media móvil de primer orden.\n",
        "\n",
        "- Modelo ARMA(1,1):\n",
        "\n",
        "  * Si se quiere capturar tanto el efecto autoregresivo como el de media móvil, se podría considerar un modelo combinado ARMA(1, 1).\n",
        "El modelo sería ARIMA(1, 0, 1).\n",
        "\n",
        "Al final, he decidido optar por el modelo ARIMA(1,0,1). La justificación se basa en los siguientes resultados:"
      ],
      "metadata": {
        "id": "iuLlnG4grYoN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Selección del Modelo ARIMA\n",
        "Basándonos en la interpretación de los gráficos ACF y PACF, podríamos considerar un modelo ARIMA(1,0,1)"
      ],
      "metadata": {
        "id": "ur_Pb2nfq6bu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ajustar el modelo ARIMA (con estacionalidad) usando los datos limpios\n",
        "model_cleaned = ARIMA(combined_data['Sales KG'], order=(1, 0, 1), seasonal_order=(1, 1, 1, 12))\n",
        "sarima_result_cleaned = model_cleaned.fit()\n",
        "\n",
        "# Resumen del modelo\n",
        "print(sarima_result_cleaned.summary())\n",
        "\n",
        "# Graficar las predicciones\n",
        "combined_data['SARIMA_Pred'] = sarima_result_cleaned.predict(start=0, end=len(combined_data)-1, dynamic=False)\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(combined_data['Sales KG'], label='Sales KG')\n",
        "plt.plot(combined_data['SARIMA_Pred'], label='SARIMA_Pred', linestyle='--')\n",
        "plt.legend()\n",
        "plt.xlabel('Fecha')\n",
        "plt.ylabel('Sales KG')\n",
        "plt.title('Predicción de Demanda Mensual con SARIMA (Datos Limpios)')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xp8eVhcQUEaC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Graficar los residuos\n",
        "residuals_cleaned = sarima_result_cleaned.resid\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(residuals_cleaned)\n",
        "plt.xlabel('Fecha')\n",
        "plt.ylabel('Residuales')\n",
        "plt.title('Residuales del Modelo SARIMA (Datos Limpios)')\n",
        "plt.show()\n",
        "\n",
        "# Graficar ACF de los residuos\n",
        "plt.figure(figsize=(12, 6))\n",
        "plot_acf(residuals_cleaned, lags=24)\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "GNl5kV3arwoy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prueba de Ljung-Box para los residuos\n",
        "ljung_box_result_cleaned = acorr_ljungbox(residuals_cleaned, lags=[10, 15, 20, 25], return_df=True)\n",
        "print(ljung_box_result_cleaned)"
      ],
      "metadata": {
        "id": "-Sxm-VTxr4Af"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcular MSE y MAE\n",
        "mse_cleaned = mean_squared_error(combined_data['Sales KG'], combined_data['SARIMA_Pred'])\n",
        "mae_cleaned = mean_absolute_error(combined_data['Sales KG'], combined_data['SARIMA_Pred'])\n",
        "\n",
        "print(f'Mean Squared Error (MSE) con datos limpios: {mse_cleaned}')\n",
        "print(f'Mean Absolute Error (MAE) con datos limpios: {mae_cleaned}')\n"
      ],
      "metadata": {
        "id": "LVfjoiAAw1iG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Definir el rango de valores para p, d, q\n",
        "p = d = q = range(0, 3)\n",
        "\n",
        "# Generar todas las combinaciones posibles de p, d y q\n",
        "pdq = list(itertools.product(p, d, q))\n",
        "\n",
        "# Generar todas las combinaciones posibles de estacionalidad\n",
        "seasonal_pdq = [(x[0], x[1], x[2], 12) for x in pdq]\n",
        "\n",
        "best_aic = float(\"inf\")\n",
        "best_params = None\n",
        "best_seasonal_params = None\n",
        "best_model = None\n",
        "\n",
        "for param in pdq:\n",
        "    for seasonal_param in seasonal_pdq:\n",
        "        try:\n",
        "            temp_model = ARIMA(combined_data['Sales KG'],\n",
        "                               order=param,\n",
        "                               seasonal_order=seasonal_param)\n",
        "            temp_result = temp_model.fit()\n",
        "\n",
        "            if temp_result.aic < best_aic:\n",
        "                best_aic = temp_result.aic\n",
        "                best_params = param\n",
        "                best_seasonal_params = seasonal_param\n",
        "                best_model = temp_result\n",
        "        except:\n",
        "            continue\n",
        "\n",
        "print(f\"Mejor AIC: {best_aic}\")\n",
        "print(f\"Mejores parámetros ARIMA: {best_params}\")\n",
        "print(f\"Mejores parámetros estacionales: {best_seasonal_params}\")\n",
        "'''\n"
      ],
      "metadata": {
        "id": "Wua5pzLnymA_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Modelo Random Forest"
      ],
      "metadata": {
        "id": "AMdHTuQkjujv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Crear características de retraso para Random Forest\n",
        "def create_lag_features(data, lag=12):\n",
        "    df = data.copy()\n",
        "    for i in range(1, lag+1):\n",
        "        df[f'lag_{i}'] = df['Sales KG'].shift(i)\n",
        "    df = df.dropna()\n",
        "    return df\n",
        "\n",
        "# Crear características con 12 retardos\n",
        "train_data_lag = create_lag_features(train_data[['Sales KG']], lag=12)\n",
        "test_data_lag = create_lag_features(test_data[['Sales KG']], lag=12)\n",
        "\n",
        "# Dividir los datos en características (X) y objetivo (y)\n",
        "X_train = train_data_lag.drop(['Sales KG'], axis=1)\n",
        "y_train = train_data_lag['Sales KG']\n",
        "X_test = test_data_lag.drop(['Sales KG'], axis=1)\n",
        "y_test = test_data_lag['Sales KG']\n",
        "\n",
        "'''\n",
        "# Crear la rejilla de parámetros\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_features': ['auto', 'sqrt', 'log2'],\n",
        "    'max_depth': [10, 20, 30],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "\n",
        "# Crear el modelo Random Forest\n",
        "rf = RandomForestRegressor(random_state=42)\n",
        "\n",
        "# Crear todas las combinaciones posibles de hiperparámetros\n",
        "param_combinations = list(ParameterGrid(param_grid))\n",
        "\n",
        "# Variables para rastrear el mejor resultado\n",
        "best_score = float(\"inf\")\n",
        "best_params = None\n",
        "\n",
        "# Búsqueda de hiperparámetros con visualización del progreso\n",
        "for params in tqdm(param_combinations, desc=\"Buscando hiperparámetros\"):\n",
        "    rf.set_params(**params)\n",
        "    rf.fit(X_train, y_train)\n",
        "    predictions = rf.predict(X_test)\n",
        "    score = mean_squared_error(y_test, predictions)\n",
        "\n",
        "    if score < best_score:\n",
        "        best_score = score\n",
        "        best_params = params\n",
        "\n",
        "print(f\"Mejores hiperparámetros para Random Forest: {best_params}\")\n",
        "print(f\"Mejor MSE: {best_score}\")\n",
        "'''\n"
      ],
      "metadata": {
        "id": "oNnvPx-SH7f0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ajustar el modelo Random Forest con los mejores hiperparámetros\n",
        "best_rf_model = RandomForestRegressor(max_depth=30, max_features='sqrt', min_samples_leaf=4, min_samples_split=2, n_estimators=200, random_state=42)\n",
        "best_rf_model.fit(X_train, y_train)\n",
        "\n",
        "# Predicciones\n",
        "rf_predictions = best_rf_model.predict(X_test)\n",
        "\n",
        "# Evaluación\n",
        "mse_rf = mean_squared_error(y_test, rf_predictions)\n",
        "mae_rf = mean_absolute_error(y_test, rf_predictions)\n",
        "print(f'Mean Squared Error (MSE) de Random Forest: {mse_rf}')\n",
        "print(f'Mean Absolute Error (MAE) de Random Forest: {mae_rf}')\n"
      ],
      "metadata": {
        "id": "2OkUflyWJN3d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Modelo LSTM"
      ],
      "metadata": {
        "id": "n38-IfmJkI2L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "random_state = 42\n",
        "tf.random.set_seed(random_state)\n",
        "\n",
        "# Escalar los datos\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "scaled_train_data = scaler.fit_transform(train_data[['Sales KG']])\n",
        "scaled_test_data = scaler.transform(test_data[['Sales KG']])\n",
        "\n",
        "# Crear características de retraso para LSTM\n",
        "def create_lag_features_lstm(data, lag=12):\n",
        "    X, y = [], []\n",
        "    for i in range(lag, len(data)):\n",
        "        X.append(data[i-lag:i, 0])\n",
        "        y.append(data[i, 0])\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "# Crear características con 12 retardos para LSTM\n",
        "lag = 12\n",
        "X_train_lstm, y_train_lstm = create_lag_features_lstm(scaled_train_data, lag=lag)\n",
        "X_test_lstm, y_test_lstm = create_lag_features_lstm(scaled_test_data, lag=lag)\n",
        "\n",
        "# Remodelar los datos para LSTM\n",
        "X_train_lstm = X_train_lstm.reshape((X_train_lstm.shape[0], X_train_lstm.shape[1], 1))\n",
        "X_test_lstm = X_test_lstm.reshape((X_test_lstm.shape[0], X_test_lstm.shape[1], 1))\n",
        "'''\n",
        "# Definir el modelo para KerasTuner\n",
        "def build_model(hp):\n",
        "    model = Sequential()\n",
        "\n",
        "    # Primera capa LSTM\n",
        "    model.add(LSTM(units=hp.Int('units_layer1', min_value=32, max_value=512, step=32),\n",
        "                   return_sequences=True, input_shape=(lag, 1)))\n",
        "    model.add(Dropout(rate=hp.Float('dropout_rate_layer1', min_value=0.0, max_value=0.5, step=0.1)))\n",
        "\n",
        "    # Segunda capa LSTM\n",
        "    model.add(LSTM(units=hp.Int('units_layer2', min_value=32, max_value=512, step=32),\n",
        "                   return_sequences=True))\n",
        "    model.add(Dropout(rate=hp.Float('dropout_rate_layer2', min_value=0.0, max_value=0.5, step=0.1)))\n",
        "\n",
        "    # Tercera capa LSTM\n",
        "    model.add(LSTM(units=hp.Int('units_layer3', min_value=32, max_value=512, step=32),\n",
        "                   return_sequences=False))\n",
        "    model.add(Dropout(rate=hp.Float('dropout_rate_layer3', min_value=0.0, max_value=0.5, step=0.1)))\n",
        "\n",
        "    # Capa de salida\n",
        "    model.add(Dense(1))\n",
        "\n",
        "    # Probar diferentes optimizadores\n",
        "    optimizer_choice = hp.Choice('optimizer', values=['adam', 'rmsprop', 'sgd'])\n",
        "    if optimizer_choice == 'adam':\n",
        "        optimizer = Adam(learning_rate=hp.Float('learning_rate', min_value=1e-4, max_value=1e-2, sampling='LOG'))\n",
        "    elif optimizer_choice == 'rmsprop':\n",
        "        optimizer = RMSprop(learning_rate=hp.Float('learning_rate', min_value=1e-4, max_value=1e-2, sampling='LOG'))\n",
        "    else:\n",
        "        optimizer = SGD(learning_rate=hp.Float('learning_rate', min_value=1e-4, max_value=1e-2, sampling='LOG'))\n",
        "\n",
        "    model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
        "    return model\n",
        "\n",
        "tuner = RandomSearch(\n",
        "    build_model,\n",
        "    objective='val_loss',\n",
        "    max_trials=30,\n",
        "    executions_per_trial=1,\n",
        "    directory='my_dir',\n",
        "    project_name='lstm_tuning'\n",
        ")\n",
        "\n",
        "# Callback de Early Stopping\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "\n",
        "tuner.search(X_train_lstm, y_train_lstm, epochs=100, validation_split=0.2, callbacks=[early_stopping])\n",
        "\n",
        "# Obtener los mejores hiperparámetros\n",
        "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "print(f\"Mejores hiperparámetros para LSTM: {best_hps.values}\")\n",
        "'''"
      ],
      "metadata": {
        "id": "POw047NqJVb-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ajustar el modelo LSTM con los mejores hiperparámetros\n",
        "\n",
        "# Construir y Entrenar el Mejor Modelo LSTM\n",
        "best_lstm_model = Sequential()\n",
        "best_lstm_model.add(LSTM(units=384, return_sequences=True, input_shape=(lag, 1)))\n",
        "best_lstm_model.add(Dropout(rate=0.4))\n",
        "best_lstm_model.add(LSTM(units=384, return_sequences=False))\n",
        "best_lstm_model.add(Dropout(rate=0.4))\n",
        "best_lstm_model.add(Dense(1))\n",
        "\n",
        "best_lstm_model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "best_lstm_model.fit(X_train_lstm, y_train_lstm, epochs=60, validation_split=0.2)\n",
        "\n",
        "# Predicciones\n",
        "lstm_predictions = best_lstm_model.predict(X_test_lstm)\n",
        "lstm_predictions = scaler.inverse_transform(lstm_predictions)\n",
        "\n",
        "# Evaluación\n",
        "y_test_lstm = y_test_lstm.reshape(-1, 1)\n",
        "y_test_lstm = scaler.inverse_transform(y_test_lstm)\n",
        "mse_lstm = mean_squared_error(y_test_lstm, lstm_predictions)\n",
        "mae_lstm = mean_absolute_error(y_test_lstm, lstm_predictions)\n",
        "print(f'Mean Squared Error (MSE) de LSTM: {mse_lstm}')\n",
        "print(f'Mean Absolute Error (MAE) de LSTM: {mae_lstm}')"
      ],
      "metadata": {
        "id": "WJV-hpMTJbxD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Modelo Prophet"
      ],
      "metadata": {
        "id": "nddyJwCJ78OV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Preparar los datos para Prophet\n",
        "df_prophet = combined_data[['Year.Month', 'Sales KG']].rename(columns={'Year.Month': 'ds', 'Sales KG': 'y'})\n",
        "\n",
        "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
        "train_size = int(len(df_prophet) * 0.8)\n",
        "train_prophet = df_prophet.iloc[:train_size]\n",
        "test_prophet = df_prophet.iloc[train_size:]\n",
        "\n",
        "# Ajustar el modelo Prophet\n",
        "model_prophet = Prophet()\n",
        "model_prophet.fit(train_prophet)\n",
        "\n",
        "# Hacer predicciones\n",
        "future = model_prophet.make_future_dataframe(periods=len(test_prophet))\n",
        "forecast = model_prophet.predict(future)\n",
        "\n",
        "# Evaluación\n",
        "y_true = test_prophet['y'].values\n",
        "y_pred = forecast['yhat'][-len(test_prophet):].values\n",
        "mse_prophet = mean_squared_error(y_true, y_pred)\n",
        "mae_prophet = mean_absolute_error(y_true, y_pred)\n",
        "print(f'Mean Squared Error (MSE) de Prophet: {mse_prophet}')\n",
        "print(f'Mean Absolute Error (MAE) de Prophet: {mae_prophet}')\n"
      ],
      "metadata": {
        "id": "VrYBPJzC6ogQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Modelo SVR"
      ],
      "metadata": {
        "id": "AUBEFyFI7_kG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear y ajustar el modelo SVR\n",
        "svr = SVR(kernel='rbf', C=1e3, gamma=0.1)\n",
        "svr.fit(X_train, y_train)\n",
        "\n",
        "# Predicciones\n",
        "svr_predictions = svr.predict(X_test)\n",
        "\n",
        "# Evaluación\n",
        "mse_svr = mean_squared_error(y_test, svr_predictions)\n",
        "mae_svr = mean_absolute_error(y_test, svr_predictions)\n",
        "print(f'Mean Squared Error (MSE) de SVR: {mse_svr}')\n",
        "print(f'Mean Absolute Error (MAE) de SVR: {mae_svr}')\n"
      ],
      "metadata": {
        "id": "UkW3b2n867WH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Modelo XGBoost"
      ],
      "metadata": {
        "id": "CBKZg2ZB8BoP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear y ajustar el modelo XGBoost\n",
        "xg_reg = xgb.XGBRegressor(objective='reg:squarederror', colsample_bytree=0.3, learning_rate=0.1, max_depth=5, alpha=10, n_estimators=10)\n",
        "xg_reg.fit(X_train, y_train)\n",
        "\n",
        "# Predicciones\n",
        "xg_predictions = xg_reg.predict(X_test)\n",
        "\n",
        "# Evaluación\n",
        "mse_xg = mean_squared_error(y_test, xg_predictions)\n",
        "mae_xg = mean_absolute_error(y_test, xg_predictions)\n",
        "print(f'Mean Squared Error (MSE) de XGBoost: {mse_xg}')\n",
        "print(f'Mean Absolute Error (MAE) de XGBoost: {mae_xg}')\n"
      ],
      "metadata": {
        "id": "DacUIjXZ6-Bq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Conclusiones\n",
        "- Modelo ARIMA:\n",
        "Es el modelo preferido para esta tarea, mostrando el mejor desempeño con los datos actuales. Es altamente efectivo para series temporales con componentes estacionales y tendencias claras, con un Mean Squared Error (MSE) de 38,357.41 y un Mean Absolute Error (MAE) de 143.34.\n",
        "\n",
        "- Modelo Random Forest:\n",
        "No es ideal para esta serie temporal específica en su forma actual, mostrando un MSE de 294,712.33 y un MAE de 416.66. Aunque puede ser útil con más características de entrada y ajuste de hiperparámetros.\n",
        "\n",
        "- Modelo LSTM:\n",
        "Actualmente no es adecuado debido a los errores extremadamente altos, con un MSE de 2.8775e+38 y un MAE de 8.2695e+18. Se requiere una revisión exhaustiva de la configuración del modelo y el preprocesamiento de los datos para mejorar su desempeño."
      ],
      "metadata": {
        "id": "M7lV7N0Z6WBA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pronóstico"
      ],
      "metadata": {
        "id": "OkjDP0oSkgNt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "combined_data.info()"
      ],
      "metadata": {
        "id": "OVKFTuOHuYZ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fijar la semilla aleatoria para reproducibilidad\n",
        "np.random.seed(42)\n",
        "\n",
        "# Asegúrate de que Year.Month esté en formato datetime\n",
        "combined_data['Year.Month'] = pd.to_datetime(combined_data['Year.Month'], format='%Y-%m')\n",
        "\n",
        "# Convertir la columna Material a tipo string\n",
        "combined_data['Material'] = combined_data['Material'].astype(str)\n",
        "\n",
        "# Ordenar los datos por Year.Month\n",
        "combined_data = combined_data.sort_values(by='Year.Month')\n",
        "\n",
        "# Materiales para los que se generarán predicciones\n",
        "materials_to_plot = ['1025298', '1030870']\n",
        "\n",
        "# Lista para almacenar los pronósticos para cada material\n",
        "forecast_results = []\n",
        "\n",
        "# Función para suavizar series temporales usando media móvil\n",
        "def moving_average(series, window_size):\n",
        "    return series.rolling(window=window_size, min_periods=1).mean()\n",
        "\n",
        "# Generar pronósticos para los materiales especificados\n",
        "for material in materials_to_plot:\n",
        "    # Filtrar los datos por material\n",
        "    material_data = combined_data[combined_data['Material'] == material]\n",
        "\n",
        "    # Verificar si hay suficientes datos para ajustar el modelo ARIMA (al menos 24 observaciones)\n",
        "    if len(material_data) < 24:\n",
        "        print(f\"No hay suficientes datos para el material {material}. Se omite.\")\n",
        "        continue\n",
        "\n",
        "    # Ajustar el modelo ARIMA a los datos históricos completos\n",
        "    try:\n",
        "        model_cleaned = ARIMA(material_data['Sales KG'], order=(1, 0, 1), seasonal_order=(1, 1, 1, 12))\n",
        "        sarima_result_cleaned = model_cleaned.fit()\n",
        "    except Exception as e:\n",
        "        print(f\"Error ajustando el modelo ARIMA para el material {material}: {e}\")\n",
        "        continue\n",
        "\n",
        "    # Generar pronósticos para los próximos 6 meses\n",
        "    forecast = sarima_result_cleaned.forecast(steps=6)\n",
        "\n",
        "    # Crear un DataFrame con los resultados\n",
        "    forecast_df = pd.DataFrame({\n",
        "        'Year.Month': pd.date_range(start=material_data['Year.Month'].max() + pd.DateOffset(months=1), periods=6, freq='M'),\n",
        "        'Material': material,\n",
        "        'Sales KG': forecast\n",
        "    })\n",
        "\n",
        "    # Agregar los resultados a la lista\n",
        "    forecast_results.append(forecast_df)\n",
        "\n",
        "# Concatenar todos los resultados en un solo DataFrame\n",
        "forecast_results_df = pd.concat(forecast_results, ignore_index=True)\n",
        "\n",
        "# Mostrar los pronósticos\n",
        "print(forecast_results_df)"
      ],
      "metadata": {
        "id": "dzX70iQMvvZ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Graficar los datos históricos y los pronósticos para cada material\n",
        "for material in materials_to_plot:\n",
        "    material_data = combined_data[combined_data['Material'] == material]\n",
        "    material_forecast = forecast_results_df[forecast_results_df['Material'] == material]\n",
        "\n",
        "    # Seleccionar los últimos 6 meses de datos históricos\n",
        "    recent_material_data = material_data.tail(6)\n",
        "\n",
        "    # Combinar datos históricos recientes y predicciones para graficar\n",
        "    combined_plot_data = pd.concat([recent_material_data, material_forecast], ignore_index=True)\n",
        "\n",
        "    # Suavizar los datos históricos y las predicciones\n",
        "    combined_plot_data['Sales KG Smoothed'] = moving_average(combined_plot_data['Sales KG'], window_size=3)\n",
        "    material_forecast['Sales KG Smoothed'] = moving_average(material_forecast['Sales KG'], window_size=3)\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(combined_plot_data['Year.Month'], combined_plot_data['Sales KG Smoothed'], label='Datos Históricos Suavizados')\n",
        "    plt.plot(material_forecast['Year.Month'], material_forecast['Sales KG Smoothed'], label='Pronóstico Suavizado', linestyle='--', color='red')\n",
        "    plt.title(f'Pronóstico de Ventas para el Material {material}')\n",
        "    plt.xlabel('Fecha')\n",
        "    plt.ylabel('Sales KG')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "g67HNbaI2InZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tareas de Pensamiento Crítico:"
      ],
      "metadata": {
        "id": "DmGcmU9WqLn3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "combined_data.info()"
      ],
      "metadata": {
        "id": "fNVTiRZy6y94"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Boxplot para identificar valores atípicos en Sales KG\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.boxplot(x='Year.Month', y='Sales KG', data=combined_data)\n",
        "plt.title('Boxplot de Sales KG por Mes')\n",
        "plt.xticks(rotation=45)\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Boxplot para identificar valores atípicos en Stockout Rate\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.boxplot(x='Year.Month', y='Stockout Rate', data=combined_data)\n",
        "plt.title('Boxplot de Stockout Rate por Mes')\n",
        "plt.xticks(rotation=45)\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "PK06PREt6slZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Análisis de Valores Atípicos y Anomalías en Ventas y Faltantes de Stock\n",
        "\n",
        "### Identificación de Valores Atípicos y Anomalías\n",
        "- **Valores Atípicos en `Sales KG`**: Se observa que hay varios valores atípicos a lo largo de los meses, especialmente entre 2018 y 2020. Estos valores podrían estar asociados a eventos específicos como promociones, cambios en la demanda o eventos externos no reflejados en los datos.\n",
        "- **Anomalías en `Stockout Rate`**: La tasa de faltantes de stock muestra variabilidad significativa con algunos picos notables. Esto podría reflejar problemas en la cadena de suministro, cambios en la política de inventario o eventos inesperados que afectaron la disponibilidad de los productos.\n",
        "\n",
        "### Contexto Histórico y Externo\n",
        "1. **Pandemia de COVID-19 (2020-2021)**:\n",
        "   - La pandemia tuvo un impacto significativo en muchas industrias, incluida la cadena de suministro. Podría haber causado interrupciones que resultaron en aumentos en la tasa de faltantes de stock y fluctuaciones en las ventas.\n",
        "   - Los boxplots muestran una variabilidad considerable en `Sales KG` y `Stockout Rate` durante 2020, lo que podría estar relacionado con las restricciones de movilidad, cambios en el comportamiento del consumidor y problemas logísticos.\n",
        "\n",
        "2. **Gobierno y Política**:\n",
        "   - **Gobierno de Santos (2014-2018)**: Durante este período se implementó el acuerdo de paz en 2016. Esto pudo haber generado un ambiente más estable para los negocios y apoyo a emprendimientos, lo que podría haber contribuido a un incremento en las ventas y una mejor planificación del inventario.\n",
        "\n",
        "### Factores Externos No Capturados\n",
        "- **Campañas de Marketing**: Eventos de marketing y promociones pueden haber influido en los picos de ventas, especialmente en los períodos donde se observan valores atípicos significativos.\n",
        "- **Acciones de Competidores**: Cambios en el mercado debido a la entrada o salida de competidores pueden haber impactado las ventas y la disponibilidad de productos.\n",
        "- **Tendencias Económicas**: Fluctuaciones en la economía, inflación, y cambios en el poder adquisitivo de los consumidores también podrían haber influido en los patrones observados.\n",
        "\n",
        "### Estrategias para Incorporar Factores Externos en el Modelo\n",
        "- **Indicadores Macroeconómicos**: Incorporar variables como el PIB, tasa de inflación y tasa de desempleo podría mejorar la precisión del modelo.\n",
        "- **Datos de Marketing**: Agregar información sobre campañas de marketing y promociones.\n",
        "- **Análisis de Sentimiento**: Usar datos de redes sociales y análisis de sentimiento para capturar la percepción del mercado y posibles cambios en la demanda.\n",
        "- **Modelos de IA Avanzados**:\n",
        "  - **Redes Neuronales Convolucionales (CNN)**: Para capturar patrones en datos temporales de alta dimensionalidad.\n",
        "  - **Redes Neuronales Recurrentes (RNN) con LSTM o GRU**: Para capturar dependencias a largo plazo en series temporales.\n",
        "  - **Modelos de Ensamble**: Combinación de múltiples modelos (por ejemplo, ARIMA con LSTM) para mejorar la robustez y precisión de las predicciones.\n",
        "  - **Transformers**: Utilización de modelos de transformers, como BERT o GPT, adaptados para series temporales.\n",
        "\n",
        "### Meses con Picos Más Altos y Más Bajos\n",
        "- **Picos más altos en Ventas (`Sales KG`)**: Marzo y Noviembre del 2020.\n",
        "- **Picos más bajos en `Stockout Rate`**: Diciembre 2018, Agosto 2020.\n",
        "\n",
        "### Insights para Empresas\n",
        "- **Períodos de Alta Demanda**: Identificar y prepararse para los picos de demanda observados en ciertos meses.\n",
        "- **Optimización del Surtido de Productos**: Ajustar el inventario y la disponibilidad de productos en función de las predicciones de demanda y la variabilidad observada en las ventas.\n",
        "- **Gestión de Faltantes de Stock**: Mejorar la cadena de suministro y las políticas de inventario para reducir los faltantes de stock, especialmente en períodos críticos.\n",
        "\n",
        "Estos insights pueden ser valiosos para mejorar la eficiencia operativa y la planificación estratégica, aprovechando tanto los datos históricos como las predicciones de demanda.\n"
      ],
      "metadata": {
        "id": "iVyoF3HEBsR6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Agradecimientos y Recomendaciones\n",
        "\n",
        "Quiero expresar mi agradecimiento a Datup por la oportunidad de participar en este desafío técnico. Este ejercicio no solo ha sido una excelente oportunidad para demostrar mis habilidades en el análisis de datos, sino también para aplicar técnicas avanzadas de modelado y análisis en un contexto real.\n",
        "\n",
        "**Recomendaciones:**\n",
        "\n",
        "1. **Segmentación de Datos y Reducción de Dimensionalidad:**\n",
        "   Recomendamos realizar una segmentación de los datos mediante técnicas de clustering, como K-means o DBSCAN, para identificar grupos homogéneos de productos o clientes. Esto permitirá un análisis más específico y la aplicación de modelos predictivos más precisos. Además, la reducción de dimensionalidad utilizando técnicas como PCA (Análisis de Componentes Principales) puede ayudar a simplificar el modelo y mejorar su rendimiento.\n",
        "\n",
        "2. **Incorporación de Factores Externos:**\n",
        "   Es crucial considerar la inclusión de variables externas que puedan afectar la demanda, como campañas de marketing, eventos económicos, estacionalidad y datos meteorológicos. La incorporación de estas variables en los modelos de predicción puede proporcionar una visión más completa y precisa del comportamiento del mercado.\n",
        "\n",
        "3. **Análisis de Causalidad:**\n",
        "   Investigar las posibles causas de las anomalías y los valores atípicos en las ventas y los faltantes de stock. Esto podría implicar la revisión de procesos internos, la calidad de los datos y otros factores externos que puedan estar influyendo en las métricas clave.\n",
        "\n",
        "4. **Evaluación Continua de Modelos:**\n",
        "   Implementar un proceso continuo de evaluación y ajuste de los modelos predictivos. La demanda y los patrones de ventas pueden cambiar con el tiempo, por lo que es esencial revisar y actualizar regularmente los modelos para mantener su precisión y relevancia.\n",
        "\n",
        "5. **Automatización de Procesos:**\n",
        "   Desarrollar sistemas automatizados para la recolección, procesamiento y análisis de datos. Esto no solo mejorará la eficiencia operativa sino que también garantizará que los datos utilizados para el análisis sean siempre actuales y precisos.\n",
        "\n",
        "Estoy seguro de que estas recomendaciones pueden ayudar a mejorar significativamente la precisión de las predicciones y la eficacia operativa de Datup. Agradezco nuevamente la oportunidad y esperamos seguir colaborando en el futuro.\n"
      ],
      "metadata": {
        "id": "Ms5ivrGrRUcc"
      }
    }
  ]
}