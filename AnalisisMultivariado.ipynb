{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "mount_file_id": "1PjvbzaZgn8duLyiAtgc2nbgsrNF1eQMM",
      "authorship_tag": "ABX9TyOnR73FZHi5h2SHocYGREJr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bonillahermes/Data_Science_Projects/blob/main/AnalisisMultivariado.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hermes Yate Bonilla\n",
        "**Data Scientist**\n",
        "---\n",
        "\n",
        "**Contact:**\n",
        "- **Email:** [bonillahermes@gmail.com](mailto:bonillahermes@gmail.com)\n",
        "- **LinkedIn:** [linkedin.com/in/bonillahermes](https://www.linkedin.com/in/bonillahermes/)\n",
        "- **GitHub:** [github.com/bonillahermes](https://github.com/bonillahermes)\n",
        "- **Webpage:** [bonillahermes.com](https://bonillahermes.com/)\n",
        "---"
      ],
      "metadata": {
        "id": "sOoGFW6AQALk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Análisis Multivariado"
      ],
      "metadata": {
        "id": "iptWIi8eQBgy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G6Id4y0CIRPa"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "# Monta tu Google Drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import scipy.stats as stats\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.express as px\n",
        "from scipy.stats import shapiro"
      ],
      "metadata": {
        "id": "nm2hF9hlJLxM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ruta del archivo Excel en tu Google Drive\n",
        "ruta_archivo = '/content/drive/MyDrive/Bases/BaseImputada.xlsx'\n",
        "\n",
        "# Cargar el archivo Excel en un DataFrame de Pandas\n",
        "df = pd.read_excel(ruta_archivo)\n",
        "\n",
        "# Mostrar las primeras filas para entender la estructura\n",
        "df.head()"
      ],
      "metadata": {
        "id": "d8Mf4WWYJW_w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Análisis Descriptivo"
      ],
      "metadata": {
        "id": "GhfbcDvWIWun"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Resumen\n",
        "\n",
        "En el estudio realizado con 137 participantes, se observa una edad promedio de aproximadamente 23.77 años, con un rango que va desde los 17 hasta los 47 años. La distribución de género muestra una mayor proporción de participantes femeninos (66.42%). La mayoría de los encuestados pertenecen a los estratos socioeconómicos medio-bajos, con un 52.55% en el estrato 2 y un 33.58% en el estrato 3. Además, un significativo 66.42% de los participantes está trabajando actualmente y un abrumador 95.62% son estudiantes universitarios. En términos políticos y religiosos, la mayoría no se identifica con ningún movimiento político (97.08%) y un 56.20% no profesa ninguna religión.\n",
        "\n",
        "En cuanto a la participación cívica, un 78.83% de los encuestados votó en las últimas elecciones. Estos datos reflejan una población joven, principalmente estudiantil, con una participación activa en el ámbito laboral y una inclinación hacia la participación electoral. A su vez, muestran una tendencia a no identificarse con movimientos políticos específicos y una inclinación menor hacia la afiliación religiosa. Este perfil demográfico y de comportamiento proporciona una comprensión valiosa del grupo estudiado, siendo de interés para investigaciones centradas en jóvenes adultos en contextos urbanos y educativos.\n"
      ],
      "metadata": {
        "id": "w2vZpLgAOT1x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Análisis descriptivo para la variable 'Edad' (P108)\n",
        "desc_edad = df['P108'].describe()\n",
        "\n",
        "# Frecuencias para las variables categóricas\n",
        "desc_genero = df['P109'].value_counts(normalize=True)  # Proporción de cada categoría\n",
        "desc_estrato = df['P110'].value_counts(normalize=True)\n",
        "desc_trabajando = df['P111'].value_counts(normalize=True)\n",
        "desc_estudiante_universitario = df['P112'].value_counts(normalize=True)\n",
        "desc_voto = df['P113'].value_counts(normalize=True)\n",
        "desc_movimiento_politico = df['P114'].value_counts(normalize=True)\n",
        "desc_religion = df['P116'].value_counts(normalize=True)\n",
        "\n",
        "# Imprimir los resultados\n",
        "print('Descripción de Edad (P108):')\n",
        "print(desc_edad)\n",
        "\n",
        "print('\\nGénero (P109):')\n",
        "print(desc_genero)\n",
        "\n",
        "print('\\nEstrato Socio-Económico (P110):')\n",
        "print(desc_estrato)\n",
        "\n",
        "print('\\n¿Se encuentra trabajando en este momento? (P111):')\n",
        "print(desc_trabajando)\n",
        "\n",
        "print('\\n¿Es estudiante universitario? (P112):')\n",
        "print(desc_estudiante_universitario)\n",
        "\n",
        "print('\\n¿Votó en las últimas elecciones? (P113):')\n",
        "print(desc_voto)\n",
        "\n",
        "print('\\n¿Pertenece a algún movimiento político? (P114):')\n",
        "print(desc_movimiento_politico)\n",
        "\n",
        "print('\\n¿Profesa alguna religión? (P116):')\n",
        "print(desc_religion)\n"
      ],
      "metadata": {
        "id": "F6fFSQLILaA2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Análisis descriptivo y gráficas para la variable Edad (P108)\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "# Histograma para la variable 'Edad'\n",
        "plt.subplot(1, 2, 1)\n",
        "sns.histplot(df['P108'], kde=True)\n",
        "plt.title('Distribución de Edad')\n",
        "plt.xlabel('Edad')\n",
        "plt.ylabel('Frecuencia')\n",
        "\n",
        "# Boxplot para la variable 'Edad'\n",
        "plt.subplot(1, 2, 2)\n",
        "sns.boxplot(y=df['P108'])\n",
        "plt.title('Boxplot de Edad')\n",
        "plt.ylabel('Edad')\n",
        "\n",
        "# Mostrar las gráficas\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "8JgOK-2BMBNQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Datos de las variables cualitativas\n",
        "genero = [66.42, 33.58]  # Femenino, Masculino\n",
        "estrato = [52.55, 33.58, 7.30, 5.84, 0.73]  # Estrato 2, 3, 1, 4, 5\n",
        "trabajando = [66.42, 33.58]  # Sí, No\n",
        "estudiante = [95.62, 4.38]  # Sí, No\n",
        "voto = [78.83, 21.17]  # Sí, No\n",
        "movimiento_politico = [97.08, 2.92]  # No, Sí\n",
        "religion = [56.20, 43.80]  # No, Sí\n",
        "\n",
        "# Etiquetas para las gráficas\n",
        "labels_genero = ['Femenino', 'Masculino']\n",
        "labels_estrato = ['Estrato 2', 'Estrato 3', 'Estrato 1', 'Estrato 4', 'Estrato 5']\n",
        "labels_si_no = ['Sí', 'No']\n",
        "\n",
        "# Creación de gráficos de barras con porcentajes\n",
        "fig, axs = plt.subplots(7, figsize=(10, 25))\n",
        "\n",
        "# Función para crear un gráfico de barras con porcentajes\n",
        "def crear_grafico_barras(data, labels, title, ax):\n",
        "    bars = ax.bar(labels, data)\n",
        "    ax.set_title(title)\n",
        "    for bar in bars:\n",
        "        yval = bar.get_height()\n",
        "        ax.text(bar.get_x() + bar.get_width()/2, yval, round(yval, 2), va='bottom')  # Agregar el porcentaje en la barra\n",
        "\n",
        "# Generar gráficos de barras para cada variable\n",
        "crear_grafico_barras(genero, labels_genero, 'Género', axs[0])\n",
        "crear_grafico_barras(estrato, labels_estrato, 'Estrato Socio-Económico', axs[1])\n",
        "crear_grafico_barras(trabajando, labels_si_no, 'Trabajando', axs[2])\n",
        "crear_grafico_barras(estudiante, labels_si_no, 'Estudiante Universitario', axs[3])\n",
        "crear_grafico_barras(voto, labels_si_no, 'Votó en últimas elecciones', axs[4])\n",
        "crear_grafico_barras(movimiento_politico, labels_si_no, 'Pertenece a movimiento político', axs[5])\n",
        "crear_grafico_barras(religion, labels_si_no, 'Profesa religión', axs[6])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "e1Mb1iHgPX0X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Validaciones"
      ],
      "metadata": {
        "id": "rfZWhOzAgWKp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "La evaluación de la confiabilidad de las escalas a través del alfa de Cronbach revela una variabilidad significativa en la coherencia interna entre las distintas dimensiones analizadas. Las escalas que evalúan 'Activismo Político en Internet', 'Actitud hacia el rol de la participación en línea' y 'Publicación de opiniones en la red' demuestran una alta fiabilidad, con alfas superiores a 0.90, superando ampliamente el umbral de 0.80 considerado adecuado para una buena fiabilidad. La 'Autoeficacia' y 'Ruptura del liderazgo político' también presentan una fiabilidad robusta, con alfas de 0.8320 y 0.8605 respectivamente. Por otro lado, la escala de 'Participación Ciudadana' muestra una fiabilidad cuestionable con un alfa de 0.5425, lo que indica la necesidad de revisión o ajuste de los ítems para mejorar su consistencia interna. Las dimensiones 'Anomia social', 'Ruptura del Tejido social', 'Presencia en comunidades digitales universitarias' y 'Apoyo a propuestas virtuales de cambio' exhiben alfas que oscilan entre 0.6423 y 0.7959, sugiriendo que, aunque son aceptables, podrían beneficiarse de una revisión para optimizar la confiabilidad de la escala."
      ],
      "metadata": {
        "id": "Pe6LnbNjxTaW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Función para calcular el alfa de Cronbach\n",
        "def cronbach_alpha(df):\n",
        "    k = df.shape[1]  # Número de ítems\n",
        "    item_var_sum = df.var(axis=0, ddof=1).sum()  # Suma de varianzas de los ítems\n",
        "    total_var = df.sum(axis=1).var(ddof=1)  # Varianza total de las puntuaciones sumadas\n",
        "    return (k / (k - 1)) * (1 - (item_var_sum / total_var))\n",
        "\n",
        "\n",
        "# Diccionario de categorías y sus respectivas variables\n",
        "variables_por_clasificacion = {\n",
        "    'Participación Ciudadana': ['P129', 'P130', 'P131', 'P132', 'P133', 'P134', 'P135', 'P136'],\n",
        "    'Autoeficacia': ['P140', 'P141', 'P142', 'P143', 'P144', 'P145', 'P146', 'P147'],\n",
        "    'Anomia social': ['P148', 'P149', 'P150', 'P151', 'P152', 'P153', 'P154', 'P155'],\n",
        "    'Ruptura del Tejido social': ['P156', 'P157', 'P158', 'P159'],\n",
        "    'Ruptura del liderazgo político': ['P160', 'P161', 'P162', 'P163'],\n",
        "    'Activismo Político en Internet': ['P164', 'P165', 'P166', 'P167', 'P168', 'P169'],\n",
        "    'Actitud hacia el rol de la participación en línea': ['P170', 'P171', 'P172', 'P173', 'P174', 'P175'],\n",
        "    'Presencia en comunidades digitales universitarias': ['P176', 'P177', 'P178', 'P179'],\n",
        "    'Apoyo a propuestas virtuales de cambio': ['P180', 'P181', 'P182', 'P183'],\n",
        "    'Publicación de opiniones en la red': ['P184', 'P185', 'P186', 'P187', 'P188']\n",
        "}\n",
        "\n",
        "# Calculamos el alfa de Cronbach para cada clasificación de variables\n",
        "alfa_cronbach_por_clasificacion = {}\n",
        "for clasificacion, items in variables_por_clasificacion.items():\n",
        "    df_clasificacion = df[items]\n",
        "    alfa_cronbach_por_clasificacion[clasificacion] = cronbach_alpha(df_clasificacion)\n",
        "\n",
        "# Mostramos los resultados\n",
        "for clasificacion, alfa in alfa_cronbach_por_clasificacion.items():\n",
        "    print(f\"Alfa de Cronbach para {clasificacion}: {alfa}\")\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ARf4epgLnd8i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Técnicas de Reducción de Dimensiones"
      ],
      "metadata": {
        "id": "QSWub01Mppm-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Seleccionar solo las columnas desde 'P124' hasta 'P188'\n",
        "df_subconjunto = df.loc[:, 'P124':'P188']\n",
        "\n",
        "# Mostrar las primeras filas del subconjunto para entender la estructura\n",
        "print(df_subconjunto.head())"
      ],
      "metadata": {
        "id": "RHXN9NWlppHL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PCA"
      ],
      "metadata": {
        "id": "ynUORzXF13_u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Preprocesamiento: Normalizar los datos del subconjunto\n",
        "scaler = StandardScaler()\n",
        "df_subconjunto_scaled = scaler.fit_transform(df_subconjunto)\n",
        "\n",
        "# Aplicar PCA\n",
        "pca = PCA(n_components=6) # Puedes ajustar el número de componentes\n",
        "principalComponents = pca.fit_transform(df_subconjunto_scaled)\n",
        "\n",
        "# Crear un DataFrame para visualizar los resultados del PCA\n",
        "pca_df = pd.DataFrame(data=principalComponents, columns=['Componente Principal 1', 'Componente Principal 2', 'Componente Principal 3', 'Componente Principal 4', 'Componente Principal 5', 'Componente Principal 6'])\n",
        "\n",
        "# Varianza explicada por cada componente\n",
        "print(\"Varianza explicada por cada componente:\")\n",
        "print(pca.explained_variance_ratio_)\n"
      ],
      "metadata": {
        "id": "QyQ7KHxfkHem"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy import stats\n",
        "\n",
        "# Prueba de Shapiro-Wilk para cada componente principal\n",
        "for i in range(principalComponents.shape[1]):\n",
        "    shapiro_test = stats.shapiro(principalComponents[:, i])\n",
        "    print(f'Shapiro-Wilk Test for Principal Component {i+1}:', shapiro_test)\n"
      ],
      "metadata": {
        "id": "s-rFW-lKIG3i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convertir 'principalComponents' a un DataFrame\n",
        "principal_components_df = pd.DataFrame(principalComponents, columns=[f'Componente Principal {i+1}' for i in range(principalComponents.shape[1])])\n",
        "\n",
        "# Unir 'principal_components_df' con el DataFrame original 'df'\n",
        "df_final = pd.concat([df, principal_components_df], axis=1)\n",
        "\n",
        "# Ahora 'df_final' contiene tanto los datos originales como los componentes principales\n",
        "# Puedes guardar este DataFrame en un nuevo archivo si es necesario\n",
        "#df_final.to_csv('tu_dataframe_con_componentes.csv', index=False)\n"
      ],
      "metadata": {
        "id": "3Pb3dpEJIo4f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_final.head()"
      ],
      "metadata": {
        "id": "poNyJRqqJoGC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import ttest_ind\n",
        "\n",
        "# Inicializamos un diccionario para almacenar los resultados de las pruebas t\n",
        "t_test_results = {}\n",
        "\n",
        "# Realizamos la prueba t para cada componente principal\n",
        "for i in range(1, 7):  # Asumimos que hay 6 componentes principales\n",
        "    # Separar los grupos por género\n",
        "    group1 = df_final[df_final['P109'] == 0][f'Componente Principal {i}']\n",
        "    group2 = df_final[df_final['P109'] == 1][f'Componente Principal {i}']\n",
        "\n",
        "    # Realizar la prueba t (Welch's t-test)\n",
        "    t_stat, p_val = ttest_ind(group1, group2, equal_var=False)\n",
        "\n",
        "    # Almacenar los resultados en el diccionario\n",
        "    t_test_results[f'Componente Principal {i}'] = {'t-statistic': t_stat, 'p-value': p_val}\n",
        "\n",
        "# Convertir el diccionario de resultados en un DataFrame para visualizarlo mejor\n",
        "t_test_results_df = pd.DataFrame(t_test_results).T\n",
        "\n",
        "# Mostrar los resultados\n",
        "print(t_test_results_df)\n"
      ],
      "metadata": {
        "id": "lk5d2JQ5Le2K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Inicializamos un diccionario para almacenar los resultados de las pruebas t\n",
        "t_test_results = {}\n",
        "\n",
        "# Realizamos la prueba t para cada componente principal\n",
        "for i in range(1, 7):  # Asumimos que hay 6 componentes principales\n",
        "    # Separar los grupos por trabajo\n",
        "    group1 = df_final[df_final['P111'] == 0][f'Componente Principal {i}']\n",
        "    group2 = df_final[df_final['P111'] == 1][f'Componente Principal {i}']\n",
        "\n",
        "    # Realizar la prueba t (Welch's t-test)\n",
        "    t_stat, p_val = ttest_ind(group1, group2, equal_var=False)\n",
        "\n",
        "    # Almacenar los resultados en el diccionario\n",
        "    t_test_results[f'Componente Principal {i}'] = {'t-statistic': t_stat, 'p-value': p_val}\n",
        "\n",
        "# Convertir el diccionario de resultados en un DataFrame para visualizarlo mejor\n",
        "t_test_results_df = pd.DataFrame(t_test_results).T\n",
        "\n",
        "# Mostrar los resultados\n",
        "print(t_test_results_df)\n"
      ],
      "metadata": {
        "id": "TuMvxJXgLmjm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Inicializamos un diccionario para almacenar los resultados de las pruebas t\n",
        "t_test_results = {}\n",
        "\n",
        "# Realizamos la prueba t para cada componente principal\n",
        "for i in range(1, 7):  # Asumimos que hay 6 componentes principales\n",
        "    # Separar los grupos por participación en las votaciones\n",
        "    group1 = df_final[df_final['P113'] == 0][f'Componente Principal {i}']\n",
        "    group2 = df_final[df_final['P113'] == 1][f'Componente Principal {i}']\n",
        "\n",
        "    # Realizar la prueba t (Welch's t-test)\n",
        "    t_stat, p_val = ttest_ind(group1, group2, equal_var=False)\n",
        "\n",
        "    # Almacenar los resultados en el diccionario\n",
        "    t_test_results[f'Componente Principal {i}'] = {'t-statistic': t_stat, 'p-value': p_val}\n",
        "\n",
        "# Convertir el diccionario de resultados en un DataFrame para visualizarlo mejor\n",
        "t_test_results_df = pd.DataFrame(t_test_results).T\n",
        "\n",
        "# Mostrar los resultados\n",
        "print(t_test_results_df)\n"
      ],
      "metadata": {
        "id": "ABiP4s2PL-Aj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Inicializamos un diccionario para almacenar los resultados de las pruebas t\n",
        "t_test_results = {}\n",
        "\n",
        "# Realizamos la prueba t para cada componente principal\n",
        "for i in range(1, 7):  # Asumimos que hay 6 componentes principales\n",
        "    # Separar los grupos por si profesa alguna religión\n",
        "    group1 = df_final[df_final['P116'] == 0][f'Componente Principal {i}']\n",
        "    group2 = df_final[df_final['P116'] == 1][f'Componente Principal {i}']\n",
        "\n",
        "    # Realizar la prueba t (Welch's t-test)\n",
        "    t_stat, p_val = ttest_ind(group1, group2, equal_var=False)\n",
        "\n",
        "    # Almacenar los resultados en el diccionario\n",
        "    t_test_results[f'Componente Principal {i}'] = {'t-statistic': t_stat, 'p-value': p_val}\n",
        "\n",
        "# Convertir el diccionario de resultados en un DataFrame para visualizarlo mejor\n",
        "t_test_results_df = pd.DataFrame(t_test_results).T\n",
        "\n",
        "# Mostrar los resultados\n",
        "print(t_test_results_df)"
      ],
      "metadata": {
        "id": "TBD0cuWBMSBC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Análisis Factorial"
      ],
      "metadata": {
        "id": "KADh4flEpJ-D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install factor-analyzer\n"
      ],
      "metadata": {
        "id": "9zCxFslrqNFz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from factor_analyzer import FactorAnalyzer\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# Normalización de los datos\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "df_scaled = scaler.fit_transform(df_subconjunto)\n",
        "\n",
        "# Crear un objeto de análisis factorial y realizar el ajuste\n",
        "fa = FactorAnalyzer(rotation=None, n_factors=df_subconjunto.shape[1])\n",
        "fa.fit(df_subconjunto)\n",
        "\n",
        "# Comprobar la cantidad óptima de factores\n",
        "# El criterio de Kaiser sugiere conservar factores con autovalores > 1\n",
        "ev, v = fa.get_eigenvalues()\n",
        "plt.scatter(range(1, df_subconjunto.shape[1]+1), ev)\n",
        "plt.plot(range(1, df_subconjunto.shape[1]+1), ev)\n",
        "plt.title('Scree Plot')\n",
        "plt.xlabel('Factores')\n",
        "plt.ylabel('Autovalor')\n",
        "plt.grid()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Qb4ZMXHVpRqp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Decidir sobre el número de factores a retener\n",
        "n = 6  # Ajustar este valor según el Scree Plot u otros criterios\n",
        "fa = FactorAnalyzer(rotation=\"varimax\", n_factors=n)\n",
        "fa.fit(df_subconjunto)\n",
        "\n",
        "# Obtener la varianza explicada por cada factor\n",
        "variance, proportional_variance, cumulative_variance = fa.get_factor_variance()\n",
        "print(\"Varianza total explicada:\\n\", cumulative_variance)"
      ],
      "metadata": {
        "id": "Ctf7we3i4AbJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ajustar el análisis factorial con rotación Varimax\n",
        "fa = FactorAnalyzer(rotation=\"varimax\", n_factors=6)  # Ajusta el número de factores según tu elección\n",
        "fa.fit(df_subconjunto)\n",
        "\n",
        "# Obtener la varianza explicada por cada factor después de la rotación\n",
        "variance, proportional_variance, cumulative_variance = fa.get_factor_variance()\n",
        "print(\"Varianza total explicada con rotación Varimax:\\n\", cumulative_variance)\n"
      ],
      "metadata": {
        "id": "3ygvnrAMskNe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtener las cargas factoriales (loadings)\n",
        "loadings = fa.loadings_\n",
        "\n",
        "# Crear un DataFrame para facilitar la visualización de las cargas factoriales\n",
        "loadings_df = pd.DataFrame(loadings, index=df_subconjunto.columns, columns=[f'Factor {i+1}' for i in range(n)])\n",
        "\n",
        "# Si quieres identificar las variables más significativas para cada factor,\n",
        "# puedes buscar las cargas más altas (absolutas) para cada factor\n",
        "for i in range(n):\n",
        "    print(f\"\\nVariables con mayor carga en Factor {i+1}:\")\n",
        "    factor_loadings = loadings_df.iloc[:, i]\n",
        "    # Puedes ajustar el umbral para tu caso específico, por ejemplo, 0.4, 0.5, 0.6 etc.\n",
        "    significant_vars = factor_loadings[abs(factor_loadings) > 0.6]\n",
        "    print(significant_vars.sort_values(ascending=False))\n"
      ],
      "metadata": {
        "id": "YPFgRy1E4ri4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Perfiles de Factores\n",
        "\n",
        "### Factor 1: Expresión y Activismo en Línea\n",
        "- **Preguntas Asociadas**: P181, P188, P187, P147, P184, P185, P182, P143, P141, P135.\n",
        "- **Interpretación**: Este factor refleja una tendencia al activismo digital y a la expresión de opiniones políticas a través de internet. Las personas con altas cargas en este factor probablemente participen activamente en la firma de peticiones, el debate de temas políticos y la manifestación de sus opiniones en línea.\n",
        "\n",
        "### Factor 2: Compromiso Político Activo en Línea\n",
        "- **Preguntas Asociadas**: P160, P164, P167, P166, P169, P163, P161, P168, P162.\n",
        "- **Interpretación**: Las cargas altas aquí sugieren un compromiso directo y activo en la política y el voluntariado digital, como trabajar para partidos políticos, organizar y firmar peticiones en línea, y la participación en grupos de discusión políticos.\n",
        "\n",
        "### Factor 3: Percepción de la Influencia Digital\n",
        "- **Preguntas Asociadas**: P170, P172, P173, P174, P175.\n",
        "- **Interpretación**: Este factor captura la creencia en la eficacia de la participación y el activismo en línea. Indica que la gente ve el internet como una herramienta poderosa para el cambio social y político y para desafiar las estructuras de poder existentes.\n",
        "\n",
        "### Factor 4: Opiniones sobre la Gobernanza\n",
        "- **Preguntas Asociadas**: P155, P154, P156, P157, P158.\n",
        "- **Interpretación**: Aquí se concentran las opiniones sobre la efectividad y justicia del gobierno. Aquellos con altas cargas en este factor probablemente perciban al gobierno como justo, eficiente y preocupado por el bienestar de la población.\n",
        "\n",
        "### Factor 5: Desconfianza a la política\n",
        "- **Preguntas Asociadas**: P149, P150, P151, P152.\n",
        "- **Interpretación**: Este factor parece relacionarse con una perspectiva cínica y desconfiada hacia la sociedad y la moralidad. Implica una creencia de que el auto-interés prevalece y que la honestidad no siempre es la mejor política.\n",
        "\n",
        "### Factor 6: Aversión a la Política\n",
        "- **Preguntas Asociadas**: P125, P126, P127, P124.\n",
        "- **Interpretación**: Indica una tendencia a evitar la política, ya sea por falta de interés o por una preferencia por no involucrarse en conversaciones políticas, posiblemente para evitar conflictos o por una visión de la política como poco útil.\n"
      ],
      "metadata": {
        "id": "_bXgWYwp7n0W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 9))\n",
        "ax = sns.heatmap(loadings, cmap='viridis', center=0, annot=True, fmt=\".2f\",\n",
        "                 linewidths=.5, cbar_kws={\"shrink\": .5})\n",
        "\n",
        "plt.title('Mapa de Calor de las Cargas Factoriales de los Componentes Principales')\n",
        "plt.xlabel('Componente Principal')\n",
        "plt.ylabel('Variable Original')\n",
        "\n",
        "# Rotar las etiquetas del eje x para mejor legibilidad\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "\n",
        "# Ajustar el tamaño de la letra de las marcas en los ejes para una mejor legibilidad\n",
        "plt.xticks(fontsize=10)\n",
        "plt.yticks(fontsize=10)\n",
        "\n",
        "# Mostrar la figura ajustada\n",
        "plt.tight_layout() # Ajusta automáticamente los parámetros de la subtrama\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "131pKy80Hcnu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cluster"
      ],
      "metadata": {
        "id": "59fnN_xltiN4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import KMeans\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Normalizar los datos antes de aplicar K-Means\n",
        "scaler = StandardScaler()\n",
        "df_subconjunto_scaled = scaler.fit_transform(df_subconjunto)\n",
        "\n",
        "# Método del codo para encontrar el número óptimo de clusters\n",
        "wcss = []  # Suma de cuadrados intra-cluster\n",
        "for i in range(1, 11):  # Prueba con varios números de clusters, por ejemplo, de 1 a 10\n",
        "    kmeans = KMeans(n_clusters=i, init='k-means++', max_iter=300, n_init=10, random_state=0)\n",
        "    kmeans.fit(df_subconjunto_scaled)\n",
        "    wcss.append(kmeans.inertia_)\n",
        "\n",
        "# Visualizar el método del codo\n",
        "plt.figure(figsize=(10, 8))\n",
        "plt.plot(range(1, 11), wcss)\n",
        "plt.title('Método del Codo')\n",
        "plt.xlabel('Número de clusters')\n",
        "plt.ylabel('WCSS')  # Suma de cuadrados dentro del cluster\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "1kL_p9dwtkKV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Asegúrate de que sea una copia independiente para evitar el SettingWithCopyWarning\n",
        "df_subconjunto = df_subconjunto.copy()\n",
        "\n",
        "# Ajustar K-Means al DataFrame\n",
        "optimal_clusters = 4  # o el número de clusters que decidiste basándote en el método del codo\n",
        "kmeans = KMeans(n_clusters=optimal_clusters, init='k-means++', max_iter=300, n_init=10, random_state=0)\n",
        "cluster_labels = kmeans.fit_predict(df_subconjunto_scaled)\n",
        "\n",
        "# Utiliza .loc para evitar el SettingWithCopyWarning al añadir la columna de clusters\n",
        "df_subconjunto.loc[:, 'Cluster'] = cluster_labels\n",
        "\n",
        "# Visualizar los clusters\n",
        "print(df_subconjunto.head())\n",
        "\n"
      ],
      "metadata": {
        "id": "QNjlGjiguGQy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Supongamos que ya has normalizado y aplicado K-Means a tus datos como se mostró en ejemplos anteriores\n",
        "\n",
        "# Aplicar PCA para reducir la dimensionalidad para visualización\n",
        "pca = PCA(n_components=2)  # Usamos 2 para facilitar la visualización 2D\n",
        "principal_components = pca.fit_transform(df_subconjunto_scaled)\n",
        "\n",
        "# Crear un nuevo DataFrame para los componentes principales\n",
        "pca_df = pd.DataFrame(data=principal_components, columns=['Componente Principal 1', 'Componente Principal 2'])\n",
        "\n",
        "# Añadir las etiquetas de clusters al DataFrame de PCA para visualizar\n",
        "pca_df['Cluster'] = cluster_labels\n",
        "\n",
        "# Graficar los clusters\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.scatterplot(x='Componente Principal 1', y='Componente Principal 2', data=pca_df, hue='Cluster', palette='viridis', alpha=0.7)\n",
        "plt.title('Visualización de Clusters')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "mq88xtDBuxd_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "\n",
        "# Asumiendo que 'df_subconjunto_scaled' son tus datos escalados y 'cluster_labels' las etiquetas de tus clusters\n",
        "\n",
        "# Aplicar PCA para reducir a 3 componentes para visualización 3D\n",
        "pca = PCA(n_components=3)\n",
        "principal_components_3d = pca.fit_transform(df_subconjunto_scaled)\n",
        "\n",
        "# Crear un nuevo DataFrame para los componentes principales\n",
        "pca_df_3d = pd.DataFrame(data=principal_components_3d, columns=['Componente Principal 1', 'Componente Principal 2', 'Componente Principal 3'])\n",
        "\n",
        "# Añadir las etiquetas de clusters al DataFrame de PCA para visualizar\n",
        "pca_df_3d['Cluster'] = cluster_labels\n",
        "\n",
        "# Graficar los clusters en 3D\n",
        "fig = plt.figure(figsize=(10, 8))\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "scatter = ax.scatter(pca_df_3d['Componente Principal 1'], pca_df_3d['Componente Principal 2'], pca_df_3d['Componente Principal 3'],\n",
        "                     c=pca_df_3d['Cluster'], cmap='viridis', label=pca_df_3d['Cluster'].unique())\n",
        "\n",
        "# Leyenda con los colores de los clusters\n",
        "legend1 = ax.legend(*scatter.legend_elements(), title=\"Clusters\")\n",
        "ax.add_artist(legend1)\n",
        "\n",
        "# Títulos de los ejes\n",
        "ax.set_xlabel('Componente Principal 1')\n",
        "ax.set_ylabel('Componente Principal 2')\n",
        "ax.set_zlabel('Componente Principal 3')\n",
        "plt.title('Visualización 3D de Clusters')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "fJhi3aCev3ID"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import KMeans\n",
        "\n",
        "# Aplicar K-Means al DataFrame con los componentes principales\n",
        "kmeans = KMeans(n_clusters=4, random_state=0)  # Ajustar n_clusters según tu elección\n",
        "cluster_labels = kmeans.fit_predict(principalComponents)\n",
        "\n",
        "# Añadir las etiquetas de clusters al DataFrame de PCA\n",
        "pca_df['Cluster'] = cluster_labels\n",
        "\n",
        "# Calcular los centros de los clusters\n",
        "cluster_centers = kmeans.cluster_centers_\n",
        "centers_df = pd.DataFrame(cluster_centers, columns=pca_df.columns[:-1])\n",
        "\n",
        "# Imprimir los centros de los clusters\n",
        "print(\"Centros de los clusters:\")\n",
        "print(centers_df)\n",
        "\n",
        "# Calcular estadísticas descriptivas para cada cluster y cada componente principal\n",
        "for i in range(kmeans.n_clusters):\n",
        "    print(f\"\\nEstadísticas descriptivas del Cluster {i}:\")\n",
        "    cluster_data = pca_df[pca_df['Cluster'] == i]\n",
        "    print(cluster_data.describe().iloc[1:,:-1])  # iloc[1:, :-1] para excluir el conteo y la columna de cluster\n",
        "\n"
      ],
      "metadata": {
        "id": "LR6TM-7dy7tV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Centros de los Clusters\n",
        "Los centros de los clusters representan el \"corazón\" de cada grupo en el espacio de componentes principales. Estos puntos centrales indican la posición media de los clusters en cada dimensión del PCA.\n",
        "\n",
        "```plaintext\n",
        "| Componente | Cluster 0 | Cluster 1 | Cluster 2 | Cluster 3 |\n",
        "|------------|-----------|-----------|-----------|-----------|\n",
        "| CP1        |    4.23   |   -3.17   |    1.15   |   -3.20   |\n",
        "| CP2        |   -1.46   |   -2.30   |    1.80   |    2.71   |\n",
        "| CP3        |    0.29   |   -0.21   |   -0.43   |    0.57   |\n",
        "| CP4        |    0.81   |   -0.83   |   -0.77   |    1.27   |\n",
        "| CP5        |   -0.04   |   -0.23   |    0.20   |    0.09   |\n",
        "| CP6        |   -0.08   |    0.46   |    0.12   |   -0.76   |\n"
      ],
      "metadata": {
        "id": "OBMv-k0wCxIK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Interpretación de las Estadísticas Descriptivas de los Clusters\n",
        "\n",
        "La interpretación de los clusters se basa en los seis componentes principales obtenidos del análisis PCA, que reflejan diferentes dimensiones de actitudes y comportamientos relacionados con la política y la participación social y digital.\n",
        "\n",
        "### Cluster 0: Altamente Influido por el Primer Componente Principal\n",
        "- **Componente Principal 1 (CP1)**: Este cluster tiene una media significativamente alta en CP1, lo que sugiere una fuerte influencia de las actitudes y comportamientos capturados por este componente. Podría indicar una tendencia hacia la participación activa y el compromiso político o social.\n",
        "- **Componente Principal 2 (CP2)**: Con una media negativa, este cluster parece diferir en aspectos capturados por el segundo componente, que podría estar relacionado con formas de participación menos directas o tradicionales.\n",
        "\n",
        "### Cluster 1: Caracterizado por Valores Negativos en CP1 y CP2\n",
        "- **CP1 y CP2**: Los valores medios negativos en estos componentes sugieren características opuestas al Cluster 0. Esto podría reflejar un grupo menos activo o comprometido con las formas de participación política o social destacadas en CP1 y CP2.\n",
        "- **Alta Variabilidad en CP3 y CP4**: Indica una diversidad de opiniones o comportamientos relacionados con las dimensiones subyacentes de estos componentes.\n",
        "\n",
        "### Cluster 2: Tendencia Positiva en CP2 y CP5\n",
        "- **CP2**: Una media positiva en CP2 sugiere características similares al Cluster 1 pero con una orientación distinta, posiblemente reflejando una forma diferente de interacción o compromiso.\n",
        "- **CP5**: Con valores medios más altos, este cluster podría estar más influenciado por aspectos relacionados con la comunicación digital o la participación en plataformas en línea.\n",
        "\n",
        "### Cluster 3: Distinción en CP2 y CP4\n",
        "- **CP2 y CP4**: Con medias positivas altas, este cluster se distingue claramente en estos componentes. Podría indicar un grupo con un enfoque particular en ciertas formas de participación política o social, o actitudes específicas hacia la gobernanza y la política.\n",
        "- **Variabilidad en CP3**: La alta desviación estándar sugiere una amplia gama de comportamientos o actitudes en esta dimensión.\n",
        "\n",
        "Estos perfiles de clusters proporcionan una comprensión profunda de cómo se agrupan los encuestados en términos de sus actitudes y comportamientos políticos y sociales. La interpretación de cada cluster ofrece pistas sobre las diferentes maneras en que las personas se relacionan con el entorno político y social, especialmente en el contexto de la era digital.\n",
        "\n"
      ],
      "metadata": {
        "id": "h-BaOYLrDrEh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sumas por ITEM"
      ],
      "metadata": {
        "id": "KsDVhVpgOLw1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definir los ítems y las variables asociadas según la imagen proporcionada\n",
        "items = {\n",
        "    'Participación Ciudadana': ['P129', 'P130', 'P131', 'P132', 'P133', 'P134', 'P135', 'P136', 'P140', 'P141', 'P142', 'P143'],\n",
        "    'Autoeficacia': ['P144', 'P145', 'P146', 'P147'],\n",
        "    'Anomia social': ['P148', 'P149', 'P150', 'P151', 'P152', 'P153'],\n",
        "    'Activismo político en Internet': ['P160', 'P161', 'P162', 'P163', 'P164', 'P165', 'P166', 'P167', 'P168', 'P169'],\n",
        "    'Actitud hacia el rol de la participación en línea': ['P170', 'P171', 'P172', 'P173', 'P174', 'P175'],\n",
        "    'Presencia en comunidades digitales universitarias': ['P176', 'P177', 'P178', 'P179'],\n",
        "    'Apoyo a propuestas virtuales de cambio': ['P180', 'P181', 'P182'],\n",
        "    'Publicación de opiniones en la red': ['P184', 'P185', 'P186', 'P187', 'P188']\n",
        "}\n",
        "\n",
        "# Crear un diccionario para almacenar los conteos por ítem\n",
        "conteos_por_item = {item: df[variables].apply(pd.Series.value_counts, axis=0).fillna(0).astype(int).sum(axis=1)\n",
        "                    for item, variables in items.items()}\n",
        "\n",
        "# Convertir el diccionario a DataFrame para una mejor visualización\n",
        "conteos_por_item_df = pd.DataFrame(conteos_por_item)\n",
        "\n",
        "# Asegurarse de que todas las posibles respuestas estén representadas\n",
        "conteos_por_item_df = conteos_por_item_df.reindex([1, 2, 3, 4, 5]).fillna(0).astype(int)\n",
        "\n",
        "# Mostrar el DataFrame de conteos\n",
        "conteos_por_item_df\n"
      ],
      "metadata": {
        "id": "35B3klw4U9_t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Configurar las visualizaciones para que aparezcan en línea (específico de los cuadernos de Jupyter)\n",
        "%matplotlib inline\n",
        "\n",
        "# Iterar sobre cada columna (ítem) en el DataFrame 'conteos_por_item_df' y crear un diagrama de barras\n",
        "for item in conteos_por_item_df.columns:\n",
        "    conteos_por_item_df[item].plot(kind='bar', figsize=(10, 6))\n",
        "\n",
        "    # Configurar título y etiquetas de los ejes\n",
        "    plt.title(f'Frecuencias de Respuestas para el Ítem: {item}')\n",
        "    plt.xlabel('Categorías de Respuestas')\n",
        "    plt.ylabel('Frecuencia')\n",
        "    plt.xticks(rotation=0)  # Mantener las etiquetas de los ejes x horizontales\n",
        "\n",
        "    # Mostrar la gráfica\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "xYEd6MxkXLoe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Clasificación de las variables por ítem según la información proporcionada\n",
        "clasificacion_items = {\n",
        "    'Participación Ciudadana': ['P129', 'P130', 'P131', 'P132', 'P133', 'P134', 'P135', 'P136', 'P140', 'P141', 'P142', 'P143'],\n",
        "    'Autoeficacia': ['P144', 'P145', 'P146', 'P147'],\n",
        "    'Anomia social': ['P148', 'P149', 'P150', 'P151', 'P152', 'P153'],\n",
        "    'Activismo político en Internet': ['P160', 'P161', 'P162', 'P163', 'P164', 'P165', 'P166', 'P167', 'P168', 'P169'],\n",
        "    'Actitud hacia el rol de la participación en línea': ['P170', 'P171', 'P172', 'P173', 'P174', 'P175'],\n",
        "    'Presencia en comunidades digitales universitarias': ['P176', 'P177', 'P178', 'P179'],\n",
        "    'Apoyo a propuestas virtuales de cambio': ['P180', 'P181', 'P182'],\n",
        "    'Publicación de opiniones en la red': ['P184', 'P185', 'P186', 'P187', 'P188']\n",
        "}\n",
        "\n",
        "# Crear un nuevo DataFrame para las sumas de las variables por ítem\n",
        "df_sumas = pd.DataFrame()\n",
        "\n",
        "# Calcular las sumas de las variables por ítem y agregarlas al nuevo DataFrame 'df_sumas'\n",
        "for item, variables in clasificacion_items.items():\n",
        "    df_sumas[item] = df[variables].sum(axis=1)"
      ],
      "metadata": {
        "id": "1wNk0_6tP6xs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Generar un histograma para cada ítem (columna) en el DataFrame 'df_sumas'\n",
        "for column in df_sumas.columns:\n",
        "    plt.figure()  # Crear una nueva figura para cada histograma\n",
        "    df_sumas[column].hist(bins=15)  # Puedes ajustar el número de bins según sea necesario\n",
        "    plt.title(f'Histograma de {column}')\n",
        "    plt.xlabel('Suma')\n",
        "    plt.ylabel('Frecuencia')\n",
        "    plt.grid(False)  # Desactivar la cuadrícula para un estilo más limpio\n",
        "    plt.show()  # Mostrar el histograma\n"
      ],
      "metadata": {
        "id": "6nFlj0VZSzat"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}